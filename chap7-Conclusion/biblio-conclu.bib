
@article{grimm_odd_2010,
  title = {The {{ODD}} Protocol: {{A}} Review and First Update},
  volume = {221},
  issn = {0304-3800},
  url = {http://www.sciencedirect.com/science/article/pii/S030438001000414X},
  doi = {10.1016/j.ecolmodel.2010.08.019},
  shorttitle = {The {{ODD}} Protocol},
  abstract = {The ‘ODD’ (Overview, Design concepts, and Details) protocol was published in 2006 to standardize the published descriptions of individual-based and agent-based models (ABMs). The primary objectives of ODD are to make model descriptions more understandable and complete, thereby making ABMs less subject to criticism for being irreproducible. We have systematically evaluated existing uses of the ODD protocol and identified, as expected, parts of ODD needing improvement and clarification. Accordingly, we revise the definition of ODD to clarify aspects of the original version and thereby facilitate future standardization of ABM descriptions. We discuss frequently raised critiques in ODD but also two emerging, and unanticipated, benefits: ODD improves the rigorous formulation of models and helps make the theoretical foundations of large models more visible. Although the protocol was designed for ABMs, it can help with documenting any large, complex model, alleviating some general objections against such models.},
  number = {23},
  journaltitle = {Ecological Modelling},
  shortjournal = {Ecological Modelling},
  date = {2010-11-24},
  pages = {2760-2768},
  keywords = {Model description,Model formulation,Model replication,Scientific communication,Standardization},
  author = {Grimm, Volker and Berger, Uta and DeAngelis, Donald L and Polhill, J Gary and Giske, Jarl and Railsback, Steven F},
  file = {/home/robin/Dropbox/Biblio/Grimm_Bergeret-al/Grimm_Bergeret-al_2010_The_ODD_protocol.pdf}
}

@inproceedings{edmonds_kiss_2005,
  langid = {english},
  title = {From {{KISS}} to {{KIDS}} – {{An}} ‘{{Anti}}-Simplistic’ {{Modelling Approach}}},
  isbn = {978-3-540-32243-6},
  url = {http://link.springer.com/chapter/10.1007/978-3-540-32243-6_11},
  abstract = {A new approach is suggested under the slogan “Keep it Descriptive Stupid” (KIDS) that encapsulates a trend in increasingly descriptive agent-based social simulation. The KIDS approach entails one starts with the simulation model that relates to the target phenomena in the most straight-forward way possible, taking into account the widest possible range of evidence, including anecdotal accounts and expert opinion. Simplification is only applied if and when the model and evidence justify this. This contrasts sharply with the KISS approach where one starts with the simplest possible model and only moves to a more complex one if forced to. An example multi-agent simulation of domestic water demand and social influence is described.},
  booktitle = {International Workshop on Multi-Agent Systems and Agent-Based Simulation},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  publisher = {{Springer Berlin Heidelberg}},
  date = {2005},
  pages = {130--144},
  keywords = {⛔ No DOI found,Artificial Intelligence (incl. Robotics),Computer Appl. in Social and Behavioral Sciences,Computer Communication Networks,Information Systems Applications (incl.Internet),Simulation},
  author = {Edmonds, Bruce and Moss, Scott},
  editor = {Davidsson, Paul and Logan, Brian and Takadama, Keiki},
  file = {/home/robin/Dropbox/Biblio/Edmonds_Moss/Edmonds_Moss_2004_From_KISS_to_KIDS–an_‘anti-simplistic’modelling.pdf;/home/robin/Zotero/storage/PSD5KAGP/10.html}
}

@article{pumain_pour_1997,
  title = {Pour Une Théorie Évolutive Des Villes},
  volume = {26},
  doi = {10.3406/spgeo.1997.1063},
  number = {2},
  journaltitle = {Espace géographique},
  date = {1997},
  pages = {119--134},
  author = {Pumain, Denise}
}

@thesis{amirpour_amraii_human-data_2018,
  title = {Human-{{Data Interaction}} in Large and {{High}}-{{Dimensional Data}}},
  institution = {{University of Pittsburgh}},
  type = {PhD Thesis},
  date = {2018},
  author = {Amirpour Amraii, Saman},
  file = {/home/robin/Dropbox/Biblio/Amirpour Amraii/Amirpour_Amraii_2018_Human-Data_Interaction_in_large_and.pdf}
}

@inproceedings{agarwal_blinkdb_2013,
  location = {{New York, NY, USA}},
  title = {{{BlinkDB}}: {{Queries}} with {{Bounded Errors}} and {{Bounded Response Times}} on {{Very Large Data}}},
  isbn = {978-1-4503-1994-2},
  url = {http://doi.acm.org/10.1145/2465351.2465355},
  doi = {10/bwrd},
  shorttitle = {{{BlinkDB}}},
  abstract = {In this paper, we present BlinkDB, a massively parallel, approximate query engine for running interactive SQL queries on large volumes of data. BlinkDB allows users to trade-off query accuracy for response time, enabling interactive queries over massive data by running queries on data samples and presenting results annotated with meaningful error bars. To achieve this, BlinkDB uses two key ideas: (1) an adaptive optimization framework that builds and maintains a set of multi-dimensional stratified samples from original data over time, and (2) a dynamic sample selection strategy that selects an appropriately sized sample based on a query's accuracy or response time requirements. We evaluate BlinkDB against the well-known TPC-H benchmarks and a real-world analytic workload derived from Conviva Inc., a company that manages video distribution over the Internet. Our experiments on a 100 node cluster show that BlinkDB can answer queries on up to 17 TBs of data in less than 2 seconds (over 200 x faster than Hive), within an error of 2-10\%.},
  booktitle = {Proceedings of the 8th {{ACM European Conference}} on {{Computer Systems}}},
  series = {{{EuroSys}} '13},
  publisher = {{ACM}},
  date = {2013},
  pages = {29--42},
  keywords = {database,estimation,query approximation,time limit},
  author = {Agarwal, Sameer and Mozafari, Barzan and Panda, Aurojit and Milner, Henry and Madden, Samuel and Stoica, Ion},
  file = {/home/robin/Dropbox/Biblio/Agarwal_Mozafariet-al/Agarwal_Mozafariet-al_2013_BlinkDB.pdf},
  note = {00474}
}

@article{turkay_progressive_2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1812.08032},
  primaryClass = {cs},
  title = {Progressive {{Data Science}}: {{Potential}} and {{Challenges}}},
  url = {http://arxiv.org/abs/1812.08032},
  shorttitle = {Progressive {{Data Science}}},
  abstract = {Data science requires time-consuming iterative manual activities. In particular, activities such as data selection, preprocessing, transformation, and mining, highly depend on iterative trial-and-error processes that could be sped up significantly by providing quick feedback on the impact of changes. The idea of progressive data science is to compute the results of changes in a progressive manner, returning a first approximation of results quickly and allow iterative refinements until converging to a final result. Enabling the user to interact with the intermediate results allows an early detection of erroneous or suboptimal choices, the guided definition of modifications to the pipeline and their quick assessment. In this paper, we discuss the progressiveness challenges arising in different steps of the data science pipeline. We describe how changes in each step of the pipeline impact the subsequent steps and outline why progressive data science will help to make the process more effective. Computing progressive approximations of outcomes resulting from changes creates numerous research challenges, especially if the changes are made in the early steps of the pipeline. We discuss these challenges and outline first steps towards progressiveness, which, we argue, will ultimately help to significantly speed-up the overall data science process.},
  date = {2018-12-19},
  keywords = {⛔ No DOI found,Computer Science - Databases,Computer Science - Human-Computer Interaction,Computer Science - Machine Learning,H.3.m,H.5.2,I.2.m,I.3.m},
  author = {Turkay, Cagatay and Pezzotti, Nicola and Binnig, Carsten and Strobelt, Hendrik and Hammer, Barbara and Keim, Daniel A. and Fekete, Jean-Daniel and Palpanas, Themis and Wang, Yunhai and Rusu, Florin},
  file = {/home/robin/Dropbox/Biblio/Turkay_Pezzottiet-al/Turkay_Pezzottiet-al_2018_Progressive_Data_Science.pdf}
}

@article{commod_modelisation_2005,
  langid = {french},
  title = {La modélisation comme outil d'accompagnement},
  volume = {13},
  issn = {1240-1307, 1765-2979},
  url = {https://www.nss-journal.org/articles/nss/abs/2005/02/nss5207/nss5207.html},
  doi = {10/b3dc2p},
  abstract = {Natures Sciences Sociétés, traite de tous les aspects de l interface homme-nature, la science faisant elle-même partie de cette interface},
  number = {2},
  journaltitle = {Natures Sciences Sociétés},
  shortjournal = {Nat. Sci. Soc.},
  date = {2005-04-01},
  pages = {165-168},
  author = {ComMod, Collectif},
  file = {/home/robin/Dropbox/Biblio/ComMod/ComMod_2005_La_modélisation_comme_outil_d'accompagnement.pdf}
}

@inreference{academie_francaise_interface_2019,
  title = {Interface},
  url = {https://www.dictionnaire-academie.fr/article/A9I1677},
  abstract = {interface},
  booktitle = {Dictionnaire de l'{{Académie}} Française, 9ème Édition},
  date = {2019},
  author = {{Académie française}}
}

@article{orr_entropydb_2019,
  langid = {english},
  title = {{{EntropyDB}}: A Probabilistic Approach to Approximate Query Processing},
  issn = {0949-877X},
  url = {https://doi.org/10.1007/s00778-019-00582-9},
  doi = {10.1007/s00778-019-00582-9},
  shorttitle = {{{EntropyDB}}},
  abstract = {We present, an interactive data exploration system that uses a probabilistic approach to generate a small, query-able summary of a dataset. Departing from traditional summarization techniques, we use the Principle of Maximum Entropy to generate a probabilistic representation of the data that can be used to give approximate query answers. We develop the theoretical framework and formulation of our probabilistic representation and show how to use it to answer queries. We then present solving techniques, give two critical optimizations to improve preprocessing time and query execution time, and explore methods to reduce query error. Lastly, we experimentally evaluate our work using a 5 GB dataset of flights within the USA and a 210 GB dataset from an astronomy particle simulation. While our current work only supports linear queries, we show that our technique can successfully answer queries faster than sampling while introducing, on average, no more error than sampling and can better distinguish between rare and nonexistent values. We also discuss extensions that can allow for data updates and linear queries over joins.},
  journaltitle = {The VLDB Journal},
  shortjournal = {The VLDB Journal},
  date = {2019-11-02},
  keywords = {Approximate query processing,Data exploration,Database summarization,Graphical models,Principle of maximum entropy,Probabilistic databases},
  author = {Orr, Laurel and Balazinska, Magdalena and Suciu, Dan},
  file = {/home/robin/Dropbox/Biblio/Orr_Balazinskaet-al/Orr_Balazinskaet-al_2019_EntropyDB.pdf}
}

@article{raimbault_space_2019,
  title = {Space {{Matters}}: {{Extending Sensitivity Analysis}} to {{Initial Spatial Conditions}} in {{Geosimulation Models}}},
  volume = {22},
  issn = {1460-7425},
  url = {http://jasss.soc.surrey.ac.uk/22/4/10.html},
  shorttitle = {Space {{Matters}}},
  number = {4},
  journaltitle = {Journal of Artificial Societies and Social Simulation},
  shortjournal = {JASSS},
  date = {2019},
  pages = {10},
  author = {Raimbault, Juste and Cottineau, Clémentine and Le Texier, Marion and Le Nechet, Florent and Reuillon, Romain}
}

@inbook{cottineau_chapter_2019,
  langid = {english},
  title = {Chapter 4: {{Incremental Territorial Modelling}}},
  url = {https://halshs.archives-ouvertes.fr/halshs-02314965},
  shorttitle = {Chapter 4},
  abstract = {The aim of this chapter is to present the main issues with embedding territorial representation and territorial dynamics in simulation models . First we depict current scientific practices, illustrated and illustrate them with select model examples. Second, propose a singular and reproducible modelling strategy, which aims specifically at describing a territorial system and its evolution. . This strategy relies on multi-modelling or incremental modelling. This chapter ends with a presentation of the limits and opportunities of this approach, with a discussion of its applicability interest to different case studies.},
  booktitle = {Geographical {{Modeling}}},
  publisher = {{ISTE}},
  date = {2019-10-14},
  author = {Cottineau, Clémentine and Chapron, Paul and Texier, Marion Le and Rey-Coyrehourcq, Sébastien},
  bookauthor = {Pumain, Denise},
  file = {/home/robin/Dropbox/Biblio/Cottineau_Chapronet-al/Cottineau_Chapronet-al_2019_Chapter_4.pdf}
}

@article{fekete_visual_2013,
  title = {Visual {{Analytics Infrastructures}}: {{From Data Management}} to {{Exploration}}},
  volume = {46},
  issn = {1558-0814},
  doi = {10.1109/MC.2013.120},
  shorttitle = {Visual {{Analytics Infrastructures}}},
  abstract = {Analysts exploring big data require more from information visualization, data analysis, and data management than these components can now deliver. New infrastructures must address the nature of exploration as well as data scale. The Web extra at http://youtu.be/K9PvskathGI is a video segment that gives an overview of how research in visual analytics can help tackle the challenges of managing and interpreting big data in various domains.},
  number = {7},
  journaltitle = {Computer},
  date = {2013-07},
  pages = {22-29},
  keywords = {data analysis,data exploration,Data handling,data management,data scale,data visualisation,Data visualization,Database systems,Hardware,hardware infrastructures,information visualization,Software architecture,software infrastructures,visual analytics,Visual analytics,visual analytics infrastructures,visualization},
  author = {Fekete, Jean-Daniel},
  file = {/home/robin/Dropbox/Biblio/Fekete/Fekete_2013_Visual_Analytics_Infrastructures.pdf}
}

@article{fekete_progressive_2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1607.05162},
  primaryClass = {cs},
  title = {Progressive {{Analytics}}: {{A Computation Paradigm}} for {{Exploratory Data Analysis}}},
  url = {http://arxiv.org/abs/1607.05162},
  shorttitle = {Progressive {{Analytics}}},
  abstract = {Exploring data requires a fast feedback loop from the analyst to the system, with a latency below about 10 seconds because of human cognitive limitations. When data becomes large or analysis becomes complex, sequential computations can no longer be completed in a few seconds and data exploration is severely hampered. This article describes a novel computation paradigm called Progressive Computation for Data Analysis or more concisely Progressive Analytics, that brings at the programming language level a low-latency guarantee by performing computations in a progressive fashion. Moving this progressive computation at the language level relieves the programmer of exploratory data analysis systems from implementing the whole analytics pipeline in a progressive way from scratch, streamlining the implementation of scalable exploratory data analysis systems. This article describes the new paradigm through a prototype implementation called ProgressiVis, and explains the requirements it implies through examples.},
  date = {2016-07-18},
  keywords = {Computer Science - Human-Computer Interaction,H.5.m,K.6.1,K.7.m},
  author = {Fekete, Jean-Daniel and Primet, Romain},
  file = {/home/robin/Dropbox/Biblio/Fekete_Primet/Fekete_Primet_2016_Progressive_Analytics.pdf}
}

@article{6876049,
  title = {Progressive Visual Analytics: User-Driven Visual Exploration of in-Progress Analytics},
  volume = {20},
  issn = {2160-9306},
  doi = {10.1109/TVCG.2014.2346574},
  number = {12},
  journaltitle = {IEEE Transactions on Visualization and Computer Graphics},
  date = {2014-12},
  pages = {1653-1662},
  keywords = {Data visualization,data visualisation,Humans,Computer Graphics,data analysis,information visualization,User-Computer Interface,learning (artificial intelligence),Visual analytics,Machine Learning,Algorithm design and analysis,Algorithms,analytic algorithms,computational speed,dataset grow,Electronic Health Records,electronic medical records,event sequences,Heuristic algorithms,in-progress analytics,information visualization techniques,interactive machine learning,Models,progressive insights,progressive visual analytic systems,Progressive visual analytics,Theoretical,Unsolicited electronic mail,user-driven visual exploration},
  author = {Stolper, C. D. and Perer, A. and Gotz, D.}
}

@book{saint1989villes,
  title = {Villes et Auto-Organisation},
  isbn = {978-2-7178-1635-8},
  pagetotal = {191},
  publisher = {{Economica}},
  date = {1989},
  author = {Pumain, Denise and Sanders, Lena and Saint-Julien, Thérèse},
  editora = {Prigogine, Ilya},
  editoratype = {collaborator}
}

@article{albert_statistical_2002,
  title = {Statistical Mechanics of Complex Networks},
  volume = {74},
  url = {https://link.aps.org/doi/10.1103/RevModPhys.74.47},
  doi = {10.1103/RevModPhys.74.47},
  abstract = {Complex networks describe a wide range of systems in nature and society. Frequently cited examples include the cell, a network of chemicals linked by chemical reactions, and the Internet, a network of routers and computers connected by physical links. While traditionally these systems have been modeled as random graphs, it is increasingly recognized that the topology and evolution of real networks are governed by robust organizing principles. This article reviews the recent advances in the field of complex networks, focusing on the statistical mechanics of network topology and dynamics. After reviewing the empirical data that motivated the recent interest in networks, the authors discuss the main models and analytical tools, covering random graphs, small-world and scale-free networks, the emerging theory of evolving networks, and the interplay between topology and the network’s robustness against failures and attacks.},
  number = {1},
  journaltitle = {Reviews of Modern Physics},
  shortjournal = {Rev. Mod. Phys.},
  date = {2002-01-30},
  pages = {47-97},
  author = {Albert, Réka and Barabási, Albert-László},
  file = {/home/robin/Dropbox/Biblio/Albert_Barabási/Albert_Barabási_2002_Statistical_mechanics_of_complex_networks.pdf}
}

@online{noauthor_dossier_nodate,
  title = {Dossier: {{Chrono}}-Chorématique Urbaine},
  url = {https://mappemonde-archive.mgm.fr/dos_chrono.html}
}


