
@article{schelling_dynamic_1971,
  title = {Dynamic Models of Segregation},
  volume = {1},
  number = {2},
  journaltitle = {Journal of mathematical sociology},
  date = {1971},
  pages = {143--186},
  author = {Schelling, Thomas C},
  note = {04241}
}

@thesis{schmitt_modelisation_2014,
  langid = {french},
  location = {{paris}},
  title = {Modélisation de la dynamique des systèmes de peuplement : de SimpopLocal à SimpopNet.},
  url = {https://tel.archives-ouvertes.fr/tel-01077891/document},
  shorttitle = {Modélisation de la dynamique des systèmes de peuplement},
  abstract = {L'évolution des villes est-elle le résultat de leurs multiples interactions ? C'est sur ce postulat que s'appuie la théorie évolutive urbaine (Pumain, 2000) pour analyser les processus de croissance des villes. Cette thèse, réalisée dans un contexte inter-disciplinaire, vise à évaluer la validité d'une telle hypothèse par la simulation informatique. Pour mener à bien ce projet, les savoirs accumulés sur la dynamique des systèmes de villes sont d'abord rassemblés afin d'en extraire les grandes caractéristiques, synthétisées sous la forme de dix fait stylisés majeurs. Deux modèles de simulation, SimpopLocal et SimpopNet, sont ensuite construits, documentés de manière standardisée, et explorés de manière systématique. Ces modèles interrogent chacun un aspect précis de la théorie évolutive urbaine: la nature des interactions interurbaines pour le premier et leur support pour le second. Les besoins associés à leur nécessaire évaluation ont guidé la conception et la mise en œuvre de deux protocoles d'explorations systématiques inédits: une méthode de calibrage automatisée, et un protocole d'analyse de sensibilité qui évalue individuellement la contribution de chaque mécanisme aux comportements simulés. Ces deux formes d'exploration confrontent de façon systématique les résultats de simulation avec les connaissances actuelles. Elles montrent que ces modèles sont capables de rendre compte de processus clés de la dynamique des systèmes des villes et prouvent pour la première fois la nécessité de mécanismes d'interactions interurbaines pour simuler des croissances proches des évolutions de systèmes réels.},
  institution = {{Université Paris I - Panthéon-Sorbonne}},
  type = {Thèse de Doctorat},
  date = {2014},
  author = {Schmitt, Clara},
  file = {/home/robin/Dropbox/Biblio/Schmitt_2014_Modélisation_de_la_dynamique_des_systèmes_de_peuplement.pdf;/home/robin/Zotero/storage/6QJQPIX9/tel-01077891.html}
}

@article{schmitt_half_2015,
  langid = {english},
  title = {Half a Billion Simulations: Evolutionary Algorithms and Distributed Computing for Calibrating the {{SimpopLocal}} Geographical Model},
  volume = {advance online publication},
  url = {https://journals.sagepub.com/doi/abs/10.1068/b130064p},
  doi = {10.1068/b130064p},
  shorttitle = {Half a {{Billion Simulations}}},
  abstract = {Multiagent geographical models integrate very large numbers of spatial interactions. In order to validate these models a large amount of computing is necessary ...},
  journaltitle = {Environment and Planning B: Planning and Design},
  shortjournal = {EPB},
  date = {2015-01-01},
  author = {Schmitt, Clara and Rey-Coyrehourcq, Sébastien and Reuillon, Romain and Pumain, Denise},
  file = {/home/robin/Dropbox/Biblio/Schmitt_Rey-Coyrehourcqet-al/Schmitt_Rey-Coyrehourcqet-al_2015_Half_a_billion_simulations.pdf}
}

@inproceedings{cura_visuagent_2014,
  location = {{Grenoble}},
  title = {{{VisuAgent}} – {{Un}} Environnement d’exploration Visuelle de Données Spatio-Temporelles Issues de Simulation},
  url = {http://rcura.github.io/VisuAgent/},
  eventtitle = {{{SAGEO}} 2014},
  series = {Session {{Demo}}},
  date = {2014-11-24},
  keywords = {ABM,Visualisation},
  author = {Cura, Robin and Boukhechba, Mehdi and Mathian, Hélène and Le Néchet, Florent and Sanders, Lena},
  note = {SAGEO 2014, Atelier Démo}
}

@inproceedings{banos2005voie,
  location = {{Orléans}},
  title = {La Voie de l’étonnement: Favoriser l’abduction Dans Les {{Systèmes}} d’{{Information Géographique}}},
  isbn = {2-913454-25-9},
  eventtitle = {Colloque {{International Géomatique}} et {{Applications}} N° 1},
  booktitle = {Apport Des {{SIG}} à La Recherche},
  publisher = {{Presses Universitaires d'Orléans}},
  date = {2005},
  pages = {237-254},
  author = {Banos, Arnaud},
  editor = {Fotsing, Jean-Marie},
  file = {/home/robin/Dropbox/Biblio/Banos/Banos_2005_La_voie_de_l’étonnement.pdf}
}

@thesis{rey-coyrehourcq_plateforme_2015,
  langid = {french},
  location = {{Paris}},
  title = {Une plateforme intégrée pour la construction et l’évaluation de modèles de simulation en géographie},
  institution = {{Université Paris I - Panthéon-Sorbonne}},
  type = {Thèse de doctorat en Géographie},
  date = {2015},
  author = {Rey-Coyrehourcq, Sébastien},
  file = {/home/robin/Dropbox/Biblio/Rey-Coyrehourcq_2015_Une_plateforme_intégrée_pour_la_construction_et_l’évaluation_de_modèles_de.pdf}
}

@article{grimm_pattern-oriented_2005,
  title = {Pattern-Oriented Modeling of Agent-Based Complex Systems: Lessons from Ecology},
  volume = {310},
  doi = {10/fk5wc4},
  number = {5750},
  journaltitle = {science},
  date = {2005},
  pages = {987-991},
  author = {Grimm, Volker and Revilla, Eloy and Berger, Uta and Jeltsch, Florian and Mooij, Wolf M. and Railsback, Steven F. and Thulke, Hans-Hermann and Weiner, Jacob and Wiegand, Thorsten and DeAngelis, Donald L.},
  file = {/home/robin/Dropbox/Biblio/Grimm_Revillaet-al/Grimm_Revillaet-al_2005_Pattern-oriented_modeling_of_agent-based_complex.pdf}
}

@article{livet2014diversite,
  title = {Diversité et Complémentarité Des Modèles Multi-Agents En Sciences Sociales},
  volume = {55},
  doi = {10/gfw9pr},
  number = {4},
  journaltitle = {Revue française de sociologie},
  date = {2014},
  pages = {689-729},
  keywords = {triangle,schema},
  author = {Livet, Pierre and Phan, Denis and Sanders, Lena},
  file = {/home/robin/Dropbox/Biblio/Livet_Phanet-al/Livet_Phanet-al_2014_Diversité_et_complémentarité_des_modèles.pdf}
}

@article{minsky_matter_1965,
  title = {Matter, Mind and Models},
  volume = {1},
  url = {https://web.media.mit.edu/~minsky/papers/MatterMindModels.html},
  journaltitle = {Proc. International Federation of Information Processing Congress},
  date = {1965},
  pages = {45-49},
  keywords = {⛔ No DOI found},
  author = {Minsky, Marvin}
}

@inproceedings{bach_review_2014,
  title = {A Review of Temporal Data Visualizations Based on Space-Time Cube Operations},
  booktitle = {Eurographics Conference on Visualization},
  date = {2014},
  keywords = {⛔ No DOI found},
  author = {Bach, Benjamin and Dragicevic, Pierre and Archambault, Daniel and Hurter, Christophe and Carpendale, Sheelagh},
  file = {/home/robin/Dropbox/Biblio/Bach_Dragicevicet-al/Bach_Dragicevicet-al_2014_A_review_of_temporal_data_visualizations_based_on.pdf}
}

@article{andrienko2018viewing,
  langid = {english},
  title = {Viewing {{Visual Analytics}} as {{Model Building}}},
  issn = {01677055},
  url = {http://doi.wiley.com/10.1111/cgf.13324},
  doi = {10/gdv9s7},
  journaltitle = {Computer Graphics Forum},
  date = {2018-01-30},
  keywords = {Visual Analysis},
  author = {Andrienko, Natalia and Lammarsch, Tim and Andrienko, Gennady and Fuchs, Georg and Keim, Daniel and Miksch, Silvia and Rind, Andrea},
  file = {/home/robin/Dropbox/Biblio/Andrienko_Lammarschet-al/Andrienko_Lammarschet-al_2018_Viewing_Visual_Analytics_as_Model_Building.pdf},
  organization = {Wiley Online Library}
}

@incollection{keim_visual_2008,
  title = {Visual Analytics: {{Definition}}, Process, and Challenges},
  shorttitle = {Visual Analytics},
  booktitle = {Information Visualization},
  publisher = {{Springer}},
  date = {2008},
  pages = {154--175},
  author = {Keim, Daniel and Andrienko, Gennady and Fekete, Jean-Daniel and Görg, Carsten and Kohlhammer, Jörn and Melançon, Guy},
  file = {/home/robin/Dropbox/Biblio/Keim_Andrienkoet-al/Keim_Andrienkoet-al_2008_Visual_analytics.pdf}
}

@article{arribasbel_geography_2018,
  langid = {english},
  title = {Geography and Computers: {{Past}}, Present, and Future},
  volume = {0},
  issn = {1749-8198},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/gec3.12403},
  doi = {10/gd56wf},
  shorttitle = {Geography and Computers},
  abstract = {The discipline of Geography has long been intertwined with the use of computers. This close interaction is likely to increase with the embeddedness of computers and concomitant growth of spatially referenced data. To better understand the current situation, and to be able to better speculate about the future, this article provides two parallel perspectives: first, we offer an historical perspective on the relationship between Geography and computers; second, we document developments—in particular the nascent field of data science—that are currently taking place outside of Geography and to which we argue the discipline should be paying close attention. Combining both perspectives, we identify the benefits of tighter integration between Geography and Data Science and argue for the establishment of a new space—that we term Geographic Data Science—in which cross-pollination could occur to the benefit of both Geography and the larger data community.},
  number = {0},
  journaltitle = {Geography Compass},
  date = {2018},
  pages = {e12403},
  keywords = {GIS,Computational Geography,Data Science,Geocomputation,Geographic Data Science},
  author = {Arribas‐Bel, Dani and Reades, Jon},
  file = {/home/robin/Dropbox/Biblio/Arribas‐Bel_Reades/Arribas‐Bel_Reades_Geography_and_computers.pdf}
}

@article{coltekin_geovisualization_2018,
  title = {Geovisualization},
  volume = {2018},
  issn = {25772848},
  url = {https://gistbok.ucgis.org/bok-topics/geovisualization},
  doi = {10.22224/gistbok/2018.2.6},
  number = {Q2},
  journaltitle = {Geographic Information Science \& Technology Body of Knowledge},
  date = {2018-04-01},
  author = {Çöltekin, Arzu and Janetzko, Halldór and Fabrikant, Sara},
  file = {/home/robin/Dropbox/Biblio/Çöltekin_Janetzkoet-al/Çöltekin_Janetzkoet-al_2018_Geovisualization.pdf}
}

@article{cherel_beyond_2015,
  langid = {english},
  title = {Beyond {{Corroboration}}: {{Strengthening Model Validation}} by {{Looking}} for {{Unexpected Patterns}}},
  volume = {10},
  issn = {1932-6203},
  url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0138212},
  doi = {10/gddwr3},
  shorttitle = {Beyond {{Corroboration}}},
  abstract = {Models of emergent phenomena are designed to provide an explanation to global-scale phenomena from local-scale processes. Model validation is commonly done by verifying that the model is able to reproduce the patterns to be explained. We argue that robust validation must not only be based on corroboration, but also on attempting to falsify the model, i.e. making sure that the model behaves soundly for any reasonable input and parameter values. We propose an open-ended evolutionary method based on Novelty Search to look for the diverse patterns a model can produce. The Pattern Space Exploration method was tested on a model of collective motion and compared to three common a priori sampling experiment designs. The method successfully discovered all known qualitatively different kinds of collective motion, and performed much better than the a priori sampling methods. The method was then applied to a case study of city system dynamics to explore the model’s predicted values of city hierarchisation and population growth. This case study showed that the method can provide insights on potential predictive scenarios as well as falsifiers of the model when the simulated dynamics are highly unrealistic.},
  number = {9},
  journaltitle = {PLOS ONE},
  shortjournal = {PLOS ONE},
  date = {2015-09-14},
  pages = {e0138212},
  keywords = {Urban geography,Archives,Evolutionary algorithms,Islands,Liquids,Population growth,Simulation and modeling,Space exploration},
  author = {Chérel, Guillaume and Cottineau, Clémentine and Reuillon, Romain},
  file = {/home/robin/Dropbox/Biblio/Chérel_Cottineauet-al/Chérel_Cottineauet-al_2015_Beyond_Corroboration.pdf}
}

@article{endert_human_2014,
  langid = {english},
  title = {The Human Is the Loop: New Directions for Visual Analytics},
  volume = {43},
  issn = {1573-7675},
  url = {https://doi.org/10.1007/s10844-014-0304-9},
  doi = {10/gfw9pn},
  shorttitle = {The Human Is the Loop},
  abstract = {Visual analytics is the science of marrying interactive visualizations and analytic algorithms to support exploratory knowledge discovery in large datasets. We argue for a shift from a ‘human in the loop’ philosophy for visual analytics to a ‘human is the loop’ viewpoint, where the focus is on recognizing analysts’ work processes, and seamlessly fitting analytics into that existing interactive process. We survey a range of projects that provide visual analytic support contextually in the sensemaking loop, and outline a research agenda along with future challenges.},
  number = {3},
  journaltitle = {Journal of Intelligent Information Systems},
  shortjournal = {J Intell Inf Syst},
  date = {2014-12-01},
  pages = {411-435},
  keywords = {Visual analytics,Clustering,Semantic interaction,Spatialization,Storytelling},
  author = {Endert, Alex and Hossain, M. Shahriar and Ramakrishnan, Naren and North, Chris and Fiaux, Patrick and Andrews, Christopher},
  file = {/home/robin/Dropbox/Biblio/Endert_Hossainet-al/Endert_Hossainet-al_2014_The_human_is_the_loop.pdf}
}

@incollection{garcia_gonzalez_visual_2019,
  langid = {english},
  location = {{Cham}},
  title = {Visual and {{Spatial Thinking}} in the {{Neogeography Age}}},
  isbn = {978-3-030-04750-4},
  url = {https://doi.org/10.1007/978-3-030-04750-4_19},
  abstract = {The twenty-first century brings us a globalized world, interlinked, virtual and mobile-connected. The Internet provides us huge amount of data that is available. It has modified the number of people who can communicate globally, the formats, the audience and the direction of information flow among others. Information changes continuously, even being modified in real time. All that seemed permanent turns ephemeral, distant becomes close. We are overwhelmed by the information we continually received. The difficulties of management provoke the increase of forms of visual communication in front of the traditional writings. Video graphic, photographic, infographic and cartographic files are growing exponentially. The ability to be connected anywhere and anytime causes location being more and more vague and space and time smaller. Place and location are soaring with the cloud’s virtualization and globalization. However, management of spatial information, geolocation and maps are increasing every day. The use of maps has been democratized thanks to the Internet, cheaper and powerful devices and geolocation. Cartography is the visual expression of spatial information. Maps have the capacity to change our perception of the territory and facts happening there. They help us to understand the world and our life. ‘Where?’ is one of the most basic question words, which are intrinsic to our existence.},
  booktitle = {Geospatial {{Challenges}} in the 21st {{Century}}},
  series = {Key {{Challenges}} in {{Geography}}},
  publisher = {{Springer International Publishing}},
  date = {2019},
  pages = {369-383},
  keywords = {GIS,Visual Analysis,Neogeography,Spatial thinking,VGI},
  author = {García González, Juan Antonio},
  editor = {Koutsopoulos, Kostis and de Miguel González, Rafael and Donert, Karl},
  options = {useprefix=true},
  file = {/home/robin/Dropbox/Biblio/García González/García_González_2019_Visual_and_Spatial_Thinking_in_the_Neogeography.pdf},
  doi = {10.1007/978-3-030-04750-4_19}
}

@article{demsar_exploring_2008,
  langid = {english},
  title = {Exploring the Spatio-Temporal Dynamics of Geographical Processes with Geographically Weighted Regression and Geovisual Analytics},
  volume = {7},
  issn = {1473-8716, 1473-8724},
  url = {http://journals.sagepub.com/doi/10.1057/PALGRAVE.IVS.9500187},
  doi = {10/c9nmt2},
  abstract = {The paper examines the potential for combining a spatial statistical methodology – Geographically Weighted Regression (GWR) – with geovisual analytical exploration to help understand complex spatio-temporal processes. This is done by applying the combined statistical – exploratory methodology to a simulated data set in which the behaviour of regression parameters was controlled across space and time. A variety of complex spatio-temporal processes was captured through space-time (i.e. as spatio-temporal) varying parameters whose values were known. The task was to see if the proposed methodology could uncover these complex processes from the data alone. The results of the experiment confirm that the combined methodology can successfully identify spatio-temporal patterns in the local GWR parameter estimates that correspond to the controlled behaviour of the original parameters.},
  number = {3-4},
  journaltitle = {Information Visualization},
  date = {2008-09},
  pages = {181-197},
  author = {Demšar, Urška and Fotheringham, A. Stewart and Charlton, Martin},
  file = {/home/robin/Dropbox/Biblio/Demšar_Fotheringhamet-al/Demšar_Fotheringhamet-al_2008_Exploring_the_spatio-temporal_dynamics_of.pdf}
}

@article{mostafa_agent_2005,
  langid = {english},
  title = {The {{Agent Visualization System}}: {{A Graphical}} and {{Textual Representation}} for {{Multi}}-{{Agent Systems}}},
  volume = {4},
  issn = {1473-8716, 1473-8724},
  url = {http://journals.sagepub.com/doi/10.1057/palgrave.ivs.9500093},
  doi = {10/fbhpg5},
  shorttitle = {The {{Agent Visualization System}}},
  abstract = {As scientists from various domains increasingly resort to agent-based simulation for a more thorough understanding of real-world phenomena, the need for a simulation environment that facilitates rapid development of multi-agent systems is growing. Such a platform should provide means of visualizing the simulated scenario. In this paper we present the agent visualization system, the first system of its kind to specifically focus on catering to the visualization needs of agent-based simulation. The proposed system is a generic add-on that equips a simulation environment with a rich set of visualization facilities offering a variety of textual and graphical browsers that allow the modeler to detect trends and relationships in the simulation scenario. Some techniques from the field of information visualization were adapted and added to the system, while others were devised especially to be used in it. Regardless of their origin, all visualization techniques were thoroughly revised to make them generic enough to fit in our generic system. Agent visualization is more challenging than traditional information visualization in more than one respect. One of them is that the data to be visualized is not static; the simulation system is constantly producing data with every time step. Moreover, the sheer amount of data, together with its diversity, call for special adaptations to ensure that the system remains responsive and generic. To illustrate the various features of the proposed agent visualization system, we present a visualization of MicroTerra; a simulation scenario involving a group of beings trying to maximize their food intake.},
  number = {2},
  journaltitle = {Information Visualization},
  date = {2005-06},
  pages = {83-94},
  author = {Mostafa, Hala and Bahgat, Reem},
  file = {/home/robin/Dropbox/Biblio/Mostafa_Bahgat_2005_The_Agent_Visualization_System.pdf}
}

@article{gotz_visualization_2019,
  langid = {english},
  title = {Visualization Model Validation via Inline Replication},
  issn = {1473-8716},
  url = {https://doi.org/10.1177/1473871618821747},
  doi = {10/gfw9pg},
  abstract = {Data visualizations typically show a representation of a data set with little to no focus on the repeatability or generalizability of the displayed trends and patterns. However, insights gleaned from these visualizations are often used as the basis for decisions about future events. Visualizations of retrospective data therefore often serve as “visual predictive models.” However, this visual predictive model approach can lead to invalid inferences. In this article, we describe an approach to visual model validation called Inline Replication. Inline Replication is closely related to the statistical techniques of bootstrap sampling and cross-validation and, like those methods, provides a non-parametric and broadly applicable technique for assessing the variance of findings from visualizations. This article describes the overall Inline Replication process and outlines how it can be integrated into both traditional and emerging “big data” visualization pipelines. It also provides examples of how Inline Replication can be integrated into common visualization techniques such as bar charts and linear regression lines. Results from an empirical evaluation of the technique and two prototype Inline Replication–based visual analysis systems are also described. The empirical evaluation demonstrates the impact of Inline Replication under different conditions, showing that both (1) the level of partitioning and (2) the approach to aggregation have a major influence over its behavior. The results highlight the trade-offs in choosing Inline Replication parameters but suggest that using n=5n=5{$<$}math display="inline" id="math1-1473871618821747" overflow="scroll" altimg="eq-00001.gif"{$><$}mrow{$><$}mi{$>$}n{$<$}/mi{$><$}mo{$>$}={$<$}/mo{$><$}mn{$>$}5{$<$}/mn{$><$}/mrow{$><$}/math{$>$} partitions is a reasonable default.},
  journaltitle = {Information Visualization},
  shortjournal = {Information Visualization},
  date = {2019-01-25},
  pages = {1473871618821747},
  author = {Gotz, David and Wang, Wenyuan and Chen, Annie T and Borland, David},
  file = {/home/robin/Dropbox/Biblio/Gotz_Wanget-al/Gotz_Wanget-al_2019_Visualization_model_validation_via_inline.pdf}
}

@thesis{wongsuphasawat_augmenting_2019,
  langid = {american},
  location = {{Seattle}},
  title = {Augmenting {{Exploratory Data Analysis}} with {{Visualization Recommendation}}},
  url = {https://digital.lib.washington.edu:443/researchworks/handle/1773/43345},
  abstract = {Exploratory data analysis is one of the key activities for understanding and discovering new insights from data.  As exploratory data analysis can involve both open-ended exploration and focused question answering, analysis tool should facilitate both exploration breadth and analysis depth. However, existing data exploration tools typically require manual chart specification, which can be tedious and prevent analysts from rapidly exploring different aspects of the data. Moreover, analysts may be blindsided by their own cognitive biases and prematurely fixate on specific questions or hypotheses. Without discipline and time, analysts may overlook important insights in the data, such as potentially confounding factors and data quality issues, and produce inaccurate results in their analyses. To help analyst perform rapid and systematic data exploration, this dissertation presents the design of mixed-initiative systems that complement manual chart specification with chart recommendation. To better understand the practice and challenges of exploratory data analysis, we first conduct an interview study with 18 data analysts. From the interview data, we characterize the goals, process, and challenges of exploratory data analysis. We then identify design opportunities for exploratory analysis tools. One major opportunity is facilitating rapid and systematic exploration with automation and guidance. The rest of the dissertation addresses this opportunity by contributing a stack of systems to augment exploratory analysis tools with chart recommendation. At the foundations of this stack, we introduce new formal languages for chart specification and recommendation. The Vega-Lite visualization grammar provides a formal representation for specifying and reasoning about charts. Building on Vega-Lite, the CompassQL query language combines partial chart specification with recommendation directives to provide a generalizable framework for chart recommendation via queries over the space of visualizations. Based on these foundations, we used the iterative design process to develop and study new recommendation-powered visual data exploration tools. Voyager enables data exploration via browsing of recommended charts, while allowing users to steer the recommendations by selecting data fields and transformations. Our user study, which compares Voyager with a traditional chart authoring tool, indicates the complementary benefits of manual authoring and recommendation browsing. Inspired by the study result, Voyager\textasciitilde{}2 blends manual and automated chart authoring in a single tool to facilitate rapid and systematic data exploration while preserving users' flexibility to directly author a broad range of charts. All of these systems have been released as open-source projects and adopted by both research and professional data science communities.},
  pagetotal = {162},
  institution = {{University of Washington}},
  type = {Thesis},
  date = {2019-02-22T17:04:22Z},
  author = {Wongsuphasawat, Kanit},
  file = {/home/robin/Dropbox/Biblio/Wongsuphasawat_2019_Augmenting_Exploratory_Data_Analysis_with_Visualization_Recommendation.pdf}
}

@article{choi2019concept,
  title = {Concept-{{Driven Visual Analytics}}: An {{Exploratory Study}} of {{Model}}-and {{Hypothesis}}-{{Based Reasoning}} with {{Visualizations}}},
  journaltitle = {Association for Computer Machinery},
  date = {2019},
  keywords = {⛔ No DOI found},
  author = {Choi, In Kwon and Childers, Taylor and Raveendranath, Nirmal Kumar and Mishra, Swati and Harris, Kyle and Reda, Khairi},
  file = {/home/robin/Dropbox/Biblio/Choi_Childerset-al/Choi_Childerset-al_2019_Concept-Driven_Visual_Analytics.pdf},
  publisher = {{Association for Computer Machinery}}
}

@article{pinchemel_geographie_1979,
  langid = {french},
  title = {Géographie et Cartographie, réflexions historiques et épistémologiques},
  volume = {56},
  url = {https://www.persee.fr/doc/bagf_0004-5322_1979_num_56_462_5108},
  doi = {10/gfw9n6},
  abstract = {Résumé. - L'histoire de la géographie et l'histoire de la cartographie semblent souvent diverger de manière regrettable. Le langage de la carte permet une représentation spécifique de la surface de la Terre : par la vision verticale (la carte supplée la vision aérienne), la représentation plane, l'échelle, la sélection des faits, les signes qui expriment ceux-ci. La géographie doit à la carte sa conceptualisation par la représentation de l'espace géographique, espace qui apparaît à travers trois processus : la toponymie, la mensuration humaine, l'humanisation. Le langage originel de la géographie est l'écriture des sociétés sur la surface terrestre, le langage cartographique est la transcription de cette écriture géographique.},
  number = {462},
  journaltitle = {Bulletin de l'Association de Géographes Français},
  date = {1979},
  pages = {239-247},
  author = {Pinchemel, Philippe}
}

@thesis{banos_pour_2013,
  langid = {french},
  location = {{Paris}},
  title = {Pour des pratiques de modélisation et de simulation libérées en Géographie et SHS},
  url = {https://halshs.archives-ouvertes.fr/tel-01112668/document},
  abstract = {Ce travail d’HDR retrace le parcours scientifique de l’auteur et repositionne dans le contexte de sa trajectoire professionnelle son investissement actuel dans l’interdisciplinarité et les sciences de la complexité. Géographe de formation, l’auteur s’est intéressé très tôt aux rapports structures/processus dans l’évolution des systèmes spatiaux et ses investigations l’ont amené à travailler sur les mobilités spatiales et certains de leurs risques ou externalités négatives associés (accidents, pollution, bruit, épidémies, congestion) dans une perspective associant étroitement la modélisation et la simulation, au service d’une démarche délibérément exploratoire. Ce positionnement a amené très tôt l’auteur à s’investir dans l’interdisciplinarité et dans la direction de collectifs interdisciplinaires, à l’image du GDR-E S4, de l’Institut des Systèmes Complexes de Paris-Ile de France ou de l’UMR Géographie-cités (CNRS-Paris1-Paris7).},
  pagetotal = {107},
  institution = {{Université Paris 1 - Panthéon-Sorbonne}},
  type = {Habilitation à Diriger des Recherches},
  date = {2013-12-02},
  keywords = {ABM},
  author = {Banos, Arnaud},
  file = {/home/robin/Dropbox/Biblio/Banos/Banos_2013_Pour_des_pratiques_de_modélisation_et_de.pdf}
}

@book{banos_modeliser_2016,
  langid = {french},
  location = {{Paris}},
  title = {Modéliser, c'est apprendre : Itinéraire d'un géographe},
  isbn = {978-2-37361-080-2},
  url = {https://www.decitre.fr/livres/modeliser-c-est-apprendre-9782373610802.html},
  shorttitle = {Modéliser, c'est apprendre},
  abstract = {Pourquoi avons-nous besoin de modéliser en sciences humaines et sociales ? Ce livre propose, dans un style volontairement très lisible et abordable par les non spécialistes, une mise en perspective originale de la nécessaire diffusion des méthodes de modélisation en sciences humaines et sociales...},
  pagetotal = {104},
  series = {Modélisations, simulations, systèmes complexes},
  publisher = {{Matériologiques}},
  date = {2016},
  author = {Banos, Arnaud},
  editora = {Bussi, Michel},
  editoratype = {collaborator}
}

@online{ribecca_chart_2018,
  langid = {british},
  title = {Chart {{Combinations}}: {{Tile Grid Maps}}},
  url = {http://datavizcatalogue.com/blog/chart-combinations-tile-grid-maps/},
  shorttitle = {Chart {{Combinations}}},
  abstract = {I wanted to document all variations of Tile Grid Maps that I've come across and also draw combinations that I think are possible.},
  journaltitle = {The Data Visualisation Catalogue Blog},
  date = {2018-06-27},
  author = {Ribecca, Severino}
}

@inbook{lenechet:hal-02025441,
  location = {{Tours}},
  title = {Transition 1~: Modéliser Les Migrations et La Colonisation de Nouveaux Territoires Par Les {{Homo}} Sapiens},
  isbn = {978-2-86906-677-9},
  url = {https://hal.archives-ouvertes.fr/hal-02025441},
  shorttitle = {Chapitre 4. {{Transition}} 1},
  booktitle = {Peupler La Terre : {{De}} La Préhistoire à l’ère Des Métropoles},
  series = {Perspectives {{Villes}} et {{Territoires}}},
  publisher = {{Presses universitaires François-Rabelais}},
  date = {2018-10-17},
  pages = {113-142},
  keywords = {peuplement,Antiquité,archeologie,géographie,histoire contemporaine,histoire de l’humanité,histoire moderne,Moyen Âge,Préhistoire,ville},
  author = {Coupé, Christophe and Hombert, Jean-Marie and Le Néchet, Florent and Mathian, Hélène and Sanders, Lena},
  bookauthor = {Sanders, Lena},
  doi = {10.4000/books.pufr.10467},
  hal_id = {hal-02025441},
  hal_version = {v1}
}

@online{hart2014parable,
  langid = {english},
  title = {Parable of the Polygons: {{A}} Playable Post on the Shape of Society},
  url = {https://ncase.me/polygons/},
  shorttitle = {Parable of the Polygons},
  journaltitle = {Explorable Explanations},
  date = {2014},
  author = {Hart, Vi and Case, Nicky}
}

@online{case_explorable_2015,
  title = {Explorable {{Explanations}}},
  url = {http://explorabl.es/},
  abstract = {a hub for learning through play},
  date = {2015-03},
  author = {Case, Nick},
  editora = {Patel, Amit and Matuschak, Andy and Benziane, Chakib and Makler, Chris and Walker, Chris and Todd, Hamish and Reich, Henry and Schaedler, Jack and Horowitz, Joshua and Rizwan, Omar and Tucker, Toph},
  editoratype = {collaborator}
}

@online{victor_simulation_2009,
  title = {Simulation as a {{Practical Tool}}},
  url = {http://worrydream.com/#!/SimulationAsAPracticalTool},
  journaltitle = {Bret Victor, beast of burden},
  date = {2009-10-19},
  author = {Victor, Bret}
}

@article{singleton_geographic_2019,
  langid = {english},
  title = {Geographic {{Data Science}}},
  volume = {0},
  issn = {1538-4632},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/gean.12194},
  doi = {10/gfx787},
  abstract = {It is widely acknowledged that the emergence of “Big Data” is having a profound and often controversial impact on the production of knowledge. In this context, Data Science has developed as an interdisciplinary approach that turns such “Big Data” into information. This article argues for the positive role that Geography can have on Data Science when being applied to spatially explicit problems; and inversely, makes the case that there is much that Geography and Geographical Analysis could learn from Data Science. We propose a deeper integration through an ambitious research agenda, including systems engineering, new methodological development, and work toward addressing some acute challenges around epistemology. We argue that such issues must be resolved in order to realize a Geographic Data Science, and that such goal would be a desirable one.},
  number = {0},
  journaltitle = {Geographical Analysis},
  date = {2019},
  author = {Singleton, Alex and Arribas‐Bel, Daniel},
  file = {/home/robin/Dropbox/Biblio/Singleton_Arribas‐Bel/Singleton_Arribas‐Bel_Geographic_Data_Science.pdf}
}

@article{robinson_design_2017,
  title = {Design and Evaluation of a Geovisual Analytics System for Uncovering Patterns in Spatio-Temporal Event Data},
  volume = {44},
  issn = {1523-0406},
  url = {https://doi.org/10.1080/15230406.2016.1139467},
  doi = {10/gf2dqm},
  abstract = {It remains difficult to develop a clear understanding of geo-located events and their relationships to one another, particularly when it comes to identifying patterns of events in less-structured textual sources, such as news feeds and social media streams. Here we present a geovisualization tool that can leverage computational methods, such as T-pattern analysis, for extracting patterns of interest from event data streams. Our system, STempo, includes coordinated-view geovisualization components designed to support visual exploration and analysis of event data, and patterns extracted from those data, in terms of time, geography, and content. Through a user evaluation, we explore the usability and utility of STempo for understanding patterns of recent political, social, economic, and military events in Syria.},
  number = {3},
  journaltitle = {Cartography and Geographic Information Science},
  date = {2017-05-04},
  pages = {216-228},
  keywords = {evaluation,Event data,geovisualization,sequence analysis,T-pattern,temporal analysis,usability,visual analytics},
  author = {Robinson, Anthony C. and Peuquet, Donna J. and Pezanowski, Scott and Hardisty, Franklin A. and Swedberg, Brian},
  file = {/home/robin/Dropbox/Biblio/Robinson_Peuquetet-al/Robinson_Peuquetet-al_2017_Design_and_evaluation_of_a_geovisual_analytics.pdf}
}

@inproceedings{hirve_survey_2019,
  langid = {english},
  title = {A {{Survey}} on {{Visualization Techniques Used}} for {{Big Data Analytics}}},
  isbn = {9789811368615},
  abstract = {According to the recent developments and efficient technology trends, Big Data has become a vital asset for all industries and organizations in modern times. Big Data is trending due to few of the main reasons such as cloud migration initiated by companies, aggregation of digital unstructured and machine data, strong administration of data security permission, and many others. As we all know, analytics is the process of drawing conclusions and finding insights from a big pile. Big Data analytics is defined as the process of querying, simplifying, obtaining insights from the huge set of data integrated in the file systems of Big Data framework. The insights obtained as the outcome of analytics should reach the end users operating on the application platform in the form of visual representation techniques such as reports, line graphs, and bar charts for better understanding and exploration about the data. We propose a case study consisting of comparison of all the existing data visualization tools and techniques available and suitable with Big Data. The paper outlines all the advantages and disadvantages of Data Visualization tools and recommends to use the one which outclasses the comparison test. The later part of paper explains about the methodology proposed using Big Data Hadoop and CDH’s Apache Impala, Hue, and Hive. The dataset chosen is imputed and fed to the Cloudera Engine for query processing and report generation. Further, the generated 2D output is given as input to Unity 3D engine for generating QR codes and 3D visualization using Marker-based technique of augmented reality.},
  booktitle = {Advances in {{Computer Communication}} and {{Computational Sciences}}},
  series = {Advances in {{Intelligent Systems}} and {{Computing}}},
  publisher = {{Springer Singapore}},
  date = {2019},
  pages = {447-459},
  keywords = {Big data,Visualization,Apache hadoop,Apache hive,Apache sqoop,Data analytics,Google charts},
  author = {Hirve, Sumit and Pradeep Reddy, C. H.},
  editor = {Bhatia, Sanjiv K. and Tiwari, Shailesh and Mishra, Krishn K. and Trivedi, Munesh C.},
  file = {/home/robin/Dropbox/Biblio/Hirve_Pradeep Reddy/Hirve_Pradeep_Reddy_2019_A_Survey_on_Visualization_Techniques_Used_for_Big.pdf}
}

@book{john1983graphical,
  langid = {english},
  location = {{Pacific Grove, California}},
  title = {Graphical Methods for Data Analysis},
  isbn = {0-87150-413-8},
  pagetotal = {407},
  series = {Statistics / {{Probability}}},
  publisher = {{Wadsworth \& Brooks / Cole Publishing Company}},
  date = {1983},
  author = {Chambers, John and Cleveland, William and Kleiner, Beat and Tukey, Paul},
  file = {/home/robin/Dropbox/Biblio/Chambers_Clevelandet-al/Chambers_Clevelandet-al_1983_Graphical_methods_for_data_analysis.djvu}
}

@article{goodwin_visualizing_2016,
  title = {Visualizing {{Multiple Variables Across Scale}} and {{Geography}}},
  volume = {22},
  issn = {1077-2626},
  doi = {10/gddwqf},
  abstract = {Comparing multiple variables to select those that effectively characterize complex entities is important in a wide variety of domains - geodemographics for example. Identifying variables that correlate is a common practice to remove redundancy, but correlation varies across space, with scale and over time, and the frequently used global statistics hide potentially important differentiating local variation. For more comprehensive and robust insights into multivariate relations, these local correlations need to be assessed through various means of defining locality. We explore the geography of this issue, and use novel interactive visualization to identify interdependencies in multivariate data sets to support geographically informed multivariate analysis. We offer terminology for considering scale and locality, visual techniques for establishing the effects of scale on correlation and a theoretical framework through which variation in geographic correlation with scale and locality are addressed explicitly. Prototype software demonstrates how these contributions act together. These techniques enable multiple variables and their geographic characteristics to be considered concurrently as we extend visual parameter space analysis (vPSA) to the spatial domain. We find variable correlations to be sensitive to scale and geography to varying degrees in the context of energy-based geodemographics. This sensitivity depends upon the calculation of locality as well as the geographical and statistical structure of the variable.},
  number = {1},
  journaltitle = {IEEE Transactions on Visualization and Computer Graphics},
  date = {2016-01},
  pages = {599-608},
  keywords = {data visualisation,Geography,Context,interactive visualization,statistical analysis,Multivariate,visual parameter space analysis,Correlation,Visualization,complex entities,Energy,energy-based geodemographics,Geodemographics,geographic correlation,geographical structure,geography,global statistics,Input variables,local correlations,Local Statistics,multivariate analysis,multivariate data sets,multivariate relations,prototype software,Prototypes,Scale,Sensitivity Analysis,spatial domain,Spatial resolution,statistical structure,Variable Selection,variable visualization,vPSA},
  author = {Goodwin, S. and Dykes, J. and Slingsby, A. and Turkay, C.},
  file = {/home/robin/Dropbox/Biblio/Goodwin_Dykeset-al/Goodwin_Dykeset-al_2016_Visualizing_Multiple_Variables_Across_Scale_and.pdf}
}

@article{cashmanuser,
  langid = {english},
  title = {A {{User}}-Based {{Visual Analytics Workflow}} for {{Exploratory Model Analysis}}},
  volume = {38, Number 3},
  issn = {1467-8659},
  doi = {10.1111/cgf.13681},
  abstract = {Many visual analytics systems allow users to interact with machine learning models towards the goals of data exploration and insight generation on a given dataset.
However, in some situations, insights may be less important than the production of an accurate predictive model for future use.
In that case, users are more interested in generating of diverse and robust predictivemodels, verifying their performance on holdout data, and selecting the most suitable model for their usage scenario.
In this paper, we consider the concept of Exploratory Model Analysis (EMA), which is defined as the process of discovering and selecting relevant models that can be used to make predictions on a data source.
We delineate the differences between EMA and the well-known term exploratory data analysis in terms of the desired outcome of the analytic process: insights into the data or a set of deployable models.
The contributions of this work are a visual analytics system workflow for EMA, a user study,and two use cases validating the effectiveness of the workflow.
We found that our system workflow enabled users to generate complex models, to assess them for various qualities, and to select the most relevant model for their task.},
  journaltitle = {Computer Graphics Forum},
  date = {2019},
  keywords = {⚠️ Invalid DOI},
  author = {Cashman, Dylan and Humayoun, Shah Rukh and Heimerl, Florian and Park, Kendall and Das, Subhajit and Thompson, John and Saket, Bahador and Mosca, Abigail and Stasko, John and Endert, Alex and others},
  file = {/home/robin/Dropbox/Biblio/Cashman_Humayounet-al/Cashman_Humayounet-al_2019_A_User-based_Visual_Analytics_Workflow_for.pdf}
}

@inproceedings{kraus_breaking_2019,
  langid = {english},
  title = {Breaking the {{Curse}} of {{Visual Data Exploration}} : {{Improving Analyses}} by {{Building Bridges}} between {{Data World}} and {{Real World}}},
  isbn = {978-1-66529-672-4},
  url = {https://kops.uni-konstanz.de/handle/123456789/45104},
  shorttitle = {Breaking the {{Curse}} of {{Visual Data Exploration}}},
  abstract = {Visual data exploration is a useful means to extract relevant information from large sets of data. The visual analytics pipeline processes data recorded from the real world to extract knowledge from gathered data. Subsequently, the resulting knowledge is associated with the real world and applied to it. However, the considered data for the analysis is usually only a small fraction of the actual real-world data and lacks above all in context information. It can easily happen that crucial context information is disregarded, leading to false conclusions about the real world. Therefore, conclusions and reasoning based on the analysis of this data pertain to the world represented by the data, and may not be valid for the real world. The purpose of this paper is to raise awareness of this discrepancy between the data world and the real world which has a high impact on the validity of analysis results in the real world. We propose two strategies which help to identify and remove specific differences between the data world and the real world. The usefulness and applicability of our strategies are demonstrated via several use cases.},
  eventtitle = {{{IVAPP}} 2019 : 10th {{International Conference}} on {{Information Visualization Theory}} and {{Applications}}},
  date = {2019},
  author = {Kraus, Matthias and Weiler, Niklas and Breitkreutz, Thorsten and Keim, Daniel A. and Stein, Manuel},
  file = {/home/robin/Dropbox/Biblio/Kraus_Weileret-al/Kraus_Weileret-al_2019_Breaking_the_Curse_of_Visual_Data_Exploration.pdf}
}

@inproceedings{livingston_query_2020,
  langid = {english},
  title = {A {{Query Generation Technique}} for {{Measuring Comprehension}} of {{Statistical Graphics}}},
  isbn = {978-3-030-20135-7},
  abstract = {In our information-driven society, there is increasing use of statistical graphics to convey information in a variety of settings, including industry, mass media, government operations, and health care. Current methods for assessing a reader’s ability to comprehend statistical graphics are custom-written, not widely accepted, usable only once, and/or reliant on subjective interpretations and inferences. We have developed a method for generating queries suitable for evaluating graph comprehension capability. Our method is based on the Sentence Verification Technique (SVT), an empirically validated framework for measuring an individual’s comprehension of prose material. Compared to ad hoc methods for testing graph comprehension, our technique is less subjective, requires less manual effort and subject matter expertise, and addresses the essential features of a given graph: values and relationships depicted, frames of reference, and style attributes. The SVT, and therefore our method, combat superficial comprehension by testing what the reader has encoded, as opposed to testing the reader’s ability at visual recall or ability to look up data without reaching real comprehension. We motivate and describe our query generation method and report on a pilot study using queries generated with it.},
  booktitle = {Advances in {{Human Factors}} in {{Training}}, {{Education}}, and {{Learning Sciences}}},
  series = {Advances in {{Intelligent Systems}} and {{Computing}}},
  publisher = {{Springer International Publishing}},
  date = {2020},
  pages = {3-14},
  keywords = {Graph comprehension,Quantitative evaluation,Sentence Verification Technique (SVT),Statistical graphics},
  author = {Livingston, Mark A. and Brock, Derek and Decker, Jonathan W. and Perzanowski, Dennis J. and Van Dolson, Christopher and Mathews, Joseph and Lulushi, Alexander S.},
  editor = {Karwowski, Waldemar and Ahram, Tareq and Nazir, Salman},
  file = {/home/robin/Dropbox/Biblio/Livingston_Brocket-al/Livingston_Brocket-al_2020_A_Query_Generation_Technique_for_Measuring.pdf}
}

@article{kent2012cartographic,
  title = {Cartographic Design and Aesthetics “{{FAQ}}”},
  url = {https://cartographicperspectives.org/index.php/journal/article/download/cp73-kent-et-al/html?inline=1},
  doi = {10/gf4cwc},
  number = {73},
  journaltitle = {Cartographic Perspectives},
  date = {2012},
  pages = {13-16},
  author = {Kent, Alexander J and Field, Kenneth and Jenny, Bernhard and Hopfstock, Anja},
  file = {/home/robin/Dropbox/Biblio/Kent_Fieldet-al/Kent_Fieldet-al_2012_Cartographic_design_and_aesthetics_“FAQ”.pdf}
}

@inproceedings{choi_visual_2019,
  langid = {english},
  location = {{Adelaide, Australia}},
  title = {Visual (Dis){{Confirmation}}: {{Validating Models}} and {{Hypotheses}} with {{Visualizations}}},
  url = {http://khreda.com/papers/Choi_IV19.pdf},
  eventtitle = {Computer {{Graphics}}, {{Imaging}} and {{Visualization}}},
  booktitle = {Proceedings of the 16th {{International Conference CGiV}}},
  date = {2019},
  keywords = {⛔ No DOI found},
  author = {Choi, In Kong and Raveendranath, Nirmal Kumar and Westerfield, Jared and Reda, Khairi},
  file = {/home/robin/Dropbox/Biblio/Choi_Raveendranathet-al/Choi_Raveendranathet-al_2019_Visual_(dis)Confirmation.pdf}
}

@article{sandouka_interactive_2019,
  title = {Interactive {{Visualizations}}: {{A Literature Review}}},
  url = {https://aisel.aisnet.org/mwais2019/8},
  shorttitle = {Interactive {{Visualizations}}},
  journaltitle = {MWAIS 2019 Proceedings},
  date = {2019-05-21},
  keywords = {⛔ No DOI found},
  author = {Sandouka, Kari},
  file = {/home/robin/Dropbox/Biblio/Sandouka/Sandouka_2019_Interactive_Visualizations.pdf}
}

@inproceedings{mcneill2019viz,
  location = {{Porto, Portugal}},
  title = {Viz-{{Blocks}}: {{Building Visualizations}} and {{Documents}} in the {{Browser}}},
  eventtitle = {{{EuroVis}} 2019},
  publisher = {{Eurographics Association}},
  date = {2019},
  keywords = {⛔ No DOI found},
  author = {McNeill, G and Hale, S},
  file = {/home/robin/Dropbox/Biblio/McNeill_Hale/McNeill_Hale_2019_Viz-Blocks.pdf}
}

@thesis{cui_towards_2019,
  langid = {english},
  title = {Towards {{Efficient Presentation And Interaction In Visual Data Analysis}}},
  url = {http://drum.lib.umd.edu/handle/1903/21931},
  abstract = {The "data explosion'' since the era of the Internet has increased data size tremendously, from several hundred Megabytes to millions of Terabytes. Large amounts of data may not fit into memory, and a proper way of handling and processing the data is necessary. Besides, analyses of such large scale data requires complex and time consuming algorithms. On the other hand, humans play an important role in steering and driving the data analysis, while there are often times when people have a hard time getting an overview of the data or knowing which analysis to run. Sometimes they may not even know where to start. There is a huge gap between the data and understanding.

An intuitive way to facilitate data analysis is to visualize it. Visualization is understandable and illustrative, while using it to support fast and rapid data exploration of large scale datasets has been a challenge for a long time. In this dissertation, we aim to facilitate efficient 

visual data exploration of large scale datasets from two perspectives: efficiency and interaction. The former indicates how users could understand the data efficiently, this depends on various factors, such as how fast data is processed and how data is presented, while the latter focuses more on the users: how they deal with the data and why they interact with the system in a particular way. 

In order to improve the efficiency of data exploration, we have looked into two steps in the visualization pipeline: rendering and processing (computations). We first address visualization rendering of large dataset through a thorough evaluation of web-based visualization performance. We evaluate and understand the page loading effects of Scalable Vector Graphics (SVG), a popular image format for interactive visualization on the web browsers. To understand the scalability of individual elements in SVG based visualization, we conduct performance tests on different types of charts, in different phases of rendering process. From the results, we have figured out optimization techniques and guidelines to achieve better performance when rendering SVG visualization. 

Secondly, we present a pure browser based distributed computing framework (VisHive) that exploits computational power from co-located idle devices for visualization. The VisHive framework speeds up web-based visualization, which is originally designed for single computer and cannot make use of additional computational resources on the client side. It takes advantage of multiple devices that today's users often have access to. VisHive constructs visualization applications that can transparently connect multiple devices into an ad-hoc cluster for local computation. It requires no specific software to be downloaded for setup.

To achieve a more interactive data analysis process, we first propose a proactive visual analytics system (DataSite) that enable users to analyze the data smoothly with a list of pre-defined algorithms. DataSite provides results through selecting and executing computations using automatic server-side computation. It utilizes computational resources exhaustively during data analysis to reduce the burden of human thinking. Analyzing results identified by these background processes are surfaced as status updates in a feed on the front-end, akin to posts in a social media feed. DataSite effectively turns data analysis into a conversation between the user and the computer, thereby reducing the cognitive load and domain knowledge requirements on users. 

Next we apply the concept of proactive data analysis to genomic data, and explore how to improve data analysis through adaptive computations in bioinformatics domain. We build Epiviz Feed, a web application that supports proactive visual and statistical analysis of genomic data. It addresses common and popular biological questions that may be asked by the analyst, and shortens the time of processing and analyzing the data with automatic computations. 

We further present a computational steering mechanism for visual analytics that prioritizes computations performed on the dataset leveraging the analyst's navigational behavior in the data. The web-based system, called Sherpa, provides computational modules for genomic data analysis, where independent algorithms calculate test statistics relevant to biological inferences about gene regulation in various tumor types and their corresponding normal tissues.},
  pagetotal = {202},
  institution = {{University of Maryland (College Park, Md.)}},
  type = {Dissertation},
  date = {2019},
  author = {Cui, Zhe},
  file = {/home/robin/Dropbox/Biblio/Cui/Cui_2019_Towards_Efficient_Presentation_And_Interaction_In.pdf},
  doi = {https://doi.org/10.13016/btf1-z47y}
}

@article{andrienko_geographic_2017,
  title = {Geographic {{Data Science}}},
  volume = {37},
  issn = {0272-1716},
  doi = {10/gf4mwf},
  abstract = {Data science methods and approaches address all stages of transition from data to knowledge and action. Visualization of this data is essential for human understanding of the subject under study, analytical reasoning about it, and generating new knowledge. Geographic data science deals with data that incorporates spatial and, often, temporal elements. The articles selected for this special issue represent a mix of theoretical approaches and novel applications of geographic data science.},
  number = {5},
  journaltitle = {IEEE Computer Graphics and Applications},
  date = {2017},
  pages = {15-17},
  keywords = {Geographic information systems,analytical reasoning,computer graphics,data visualization,Visual analytics,visual analytics,computer graphics research,data handling,Data science,data science methods,geographic data science,geographic information science,geographic information systems,human understanding,Special issues and sections,temporal elements},
  author = {Andrienko, G. and Andrienko, N. and Weibel, R.},
  file = {/home/robin/Dropbox/Biblio/Andrienko_Andrienkoet-al/Andrienko_Andrienkoet-al_2017_Geographic_Data_Science.pdf}
}

@article{cui_confluent-drawing_2019,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1906.10017},
  primaryClass = {cs},
  title = {Confluent-{{Drawing Parallel Coordinates}}: {{Web}}-{{Based Interactive Visual Analytics}} of {{Large Multi}}-{{Dimensional Data}}},
  url = {http://arxiv.org/abs/1906.10017},
  shorttitle = {Confluent-{{Drawing Parallel Coordinates}}},
  abstract = {Parallel coordinates plot is one of the most popular and widely used visualization techniques for multi-dimensional data sets. Its main challenges for large-scale data sets are visual clutter and overplotting which hamper the recognition of patterns and trends in the data. In this paper, we propose a confluent drawing approach of parallel coordinates to support the web-based interactive visual analytics of large multi-dimensional data. The proposed method maps multi-dimensional data to node-link diagrams through the data binning-based clustering for each dimension. It uses density-based confluent drawing to visualize clusters and edges to reduce visual clutter and overplotting. Its rendering time is independent of the number of data items. It supports interactive visualization of large data sets without hardware acceleration in a normal web browser. Moreover, we design interactions to control the data binning process with this approach to support interactive visual analytics of large multi-dimensional data sets. Based on the proposed approach, we implement a web-based visual analytics application. The efficiency of the proposed method is examined through experiments on several data sets. The effectiveness of the proposed method is evaluated through a user study, in which two typical tasks of parallel coordinates plot are performed by participants to compare the proposed method with another parallel coordinates bundling technique. Results show that the proposed method significantly enhances the web-based interactive visual analytics of large multi-dimensional data.},
  date = {2019-06-14},
  keywords = {Computer Science - Human-Computer Interaction,⛔ No DOI found,Computer Science - Computer Vision and Pattern Recognition},
  author = {Cui, Wenqiang and Strazdins, Girts and Wang, Hao},
  file = {/home/robin/Dropbox/Biblio/Cui_Strazdinset-al/Cui_Strazdinset-al_2019_Confluent-Drawing_Parallel_Coordinates.pdf}
}

@article{saket_liger_2019,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1907.08345},
  primaryClass = {cs},
  title = {Liger: {{Combining Interaction Paradigms}} for {{Visual Analysis}}},
  url = {http://arxiv.org/abs/1907.08345},
  shorttitle = {Liger},
  abstract = {Visualization tools usually leverage a single interaction paradigm (e.g., manual view specification, visualization by demonstration, etc.), which fosters the process of visualization construction. A large body of work has investigated the effectiveness of individual interaction paradigms, building an understanding of advantages and disadvantages of each in isolation. However, how can we leverage the benefits of multiple interaction paradigms by combining them into a single tool? We currently lack a holistic view of how interaction paradigms that use the same input modality (e.g., mouse) can be combined into a single tool and how people use such tools. To investigate opportunities and challenges in combining paradigms, we first created a multi-paradigm prototype (Liger) that combines two mouse-based interaction paradigms (manual view specification and visualization by demonstration) in a unified tool. We then conducted an exploratory study with Liger, providing initial evidence that people 1) use both paradigms interchangeably, 2) seamlessly switch between paradigms based on the operation at hand, and 3) choose to successfully complete a single operation using a combination of both paradigms.},
  date = {2019-07-18},
  keywords = {Computer Science - Human-Computer Interaction,⛔ No DOI found},
  author = {Saket, Bahador and Jiang, Lei and Perin, Charles and Endert, Alex},
  file = {/home/robin/Dropbox/Biblio/Saket_Jianget-al/Saket_Jianget-al_2019_Liger.pdf}
}

@inproceedings{tropmann-frick_towards_2020,
  langid = {english},
  title = {Towards {{Visual Data Science}} - {{An Exploration}}},
  isbn = {978-3-030-25629-6},
  abstract = {Visual perception is one of the most essential abilities for humans. This ability allows us to discover the world around us and to understand interdependencies with regard to both global context and particular concrete problem statement. We present in this paper an exploration of visualization and visual analytics approaches. Thereby, we focus on the field of data science with data-centric analytic methods and applications. Data science is closing the gap between visualization techniques, traditional hypothesis-driven methods and processing of mostly huge, heterogeneous and noisy data. A combination of smart visualization, advanced analytical methods and additional (domain) knowledge, mostly provided by humans, makes it possible to gain insights and discover new opportunities for problem solving.},
  booktitle = {Human {{Interaction}} and {{Emerging Technologies}}},
  series = {Advances in {{Intelligent Systems}} and {{Computing}}},
  publisher = {{Springer International Publishing}},
  date = {2020},
  pages = {371-377},
  keywords = {Visual analytics,Visualization,Data science,Visual interaction},
  author = {Tropmann-Frick, Marina and Andersen, Jakob Smedegaard},
  editor = {Ahram, Tareq and Taiar, Redha and Colson, Serge and Choplin, Arnaud},
  file = {/home/robin/Dropbox/Biblio/Tropmann-Frick_Andersen/Tropmann-Frick_Andersen_2020_Towards_Visual_Data_Science_-_An_Exploration.pdf}
}

@article{dimara_what_2020,
  title = {What Is {{Interaction}} for {{Data Visualization}}?},
  url = {https://hal.archives-ouvertes.fr/hal-02197062},
  abstract = {Interaction is fundamental to data visualization, but what "interaction" means in the context of visualization is ambiguous and confusing. We argue that this confusion is due to a lack of consensual definition. To tackle this problem, we start by synthesizing an inclusive view of interaction in the visualization community-including insights from information visualization, visual analytics and scientific visualization, as well as the input of both senior and junior visualization researchers. Once this view takes shape, we look at how interaction is defined in the field of human-computer interaction (HCI). By extracting commonalities and differences between the views of interaction in visualization and in HCI, we synthesize a definition of interaction for visualization. Our definition is meant to be a thinking tool and inspire novel and bolder interaction design practices. We hope that by better understanding what interaction in visualization is and what it can be, we will enrich the quality of interaction in visualization systems and empower those who use them.},
  journaltitle = {IEEE Transactions on Visualization and Computer Graphics},
  date = {2020},
  keywords = {interaction,visualization,⛔ No DOI found,data,definition,human-computer interaction},
  author = {Dimara, Evanthia and Perin, Charles},
  file = {/home/robin/Dropbox/Biblio/Dimara_Perin/Dimara_Perin_2020_What_is_Interaction_for_Data_Visualization.pdf}
}

@article{wilkening_towards_2019,
  langid = {english},
  title = {Towards {{Spatial Data Science}}: {{Bridging}} the {{Gap}} between {{GIS}}, {{Cartography}} and {{Data Science}}},
  volume = {1},
  issn = {-},
  url = {https://www.abstr-int-cartogr-assoc.net/1/403/2019/},
  doi = {10/gf7hmj},
  shorttitle = {Towards {{Spatial Data Science}}},
  abstract = {{$<$}p{$><$}strong{$>$}Abstract.{$<$}/strong{$>$} Data is regarded as the oil of the 21st century, and the concept of data science has received increasing attention in the last years. These trends are mainly caused by the rise of big data \&ndash; data that is big in terms of volume, variety and velocity. Consequently, data scientists are required to make sense of these large datasets. Companies have problems acquiring talented people to solve data science problems. This is not surprising, as employers often expect skillsets that can hardly be found in one person: Not only does a data scientist need to have a solid background in machine learning, statistics and various programming languages, but often also in IT systems architecture, databases, complex mathematics. Above all, she should have a strong non-technical domain expertise in her field (see Figure 1).{$<$}/p{$><$}p{$>$}As it is widely accepted that 80\% of data has a spatial component, developments in data science could provide exciting new opportunities for GIS and cartography: Cartographers are experts in spatial data visualization, and often also very skilled in statistics, data pre-processing and analysis in general. The cartographers’ skill levels often depend on the degree to which cartography programs at universities focus on the “front end” (visualisation) of a spatial data and leave the “back end” (modelling, gathering, processing, analysis) to GIScientists. In many university curricula, these front-end and back-end distinctions between cartographers and GIScientists are not clearly defined, and the boundaries are somewhat blurred.{$<$}/p{$><$}p{$>$}In order to become good data scientists, cartographers and GIScientists need to acquire certain additional skills that are often beyond their university curricula. These skills include programming, machine learning and data mining. These are important technologies for extracting knowledge big spatial data sets, and thereby the logical advancement to “traditional” geoprocessing, which focuses on “traditional” (small, structured, static) datasets such shapefiles or feature classes.{$<$}/p{$><$}p{$>$}To bridge the gap between spatial sciences (such as GIS and cartography) and data science, we need an integrated framework of “spatial data science” (Figure 2).{$<$}/p{$><$}p{$>$}Spatial sciences focus on causality, theory-based approaches to explain why things are happening in space. In contrast, the scope of data science is to find similar patterns in big datasets with techniques of machine learning and data mining \&ndash; often without considering spatial concepts (such as topology, spatial indexing, spatial autocorrelation, modifiable area unit problems, map projections and coordinate systems, uncertainty in measurement etc.).{$<$}/p{$><$}p{$>$}Spatial data science could become the core competency of GIScientists and cartographers who are willing to integrate methods from the data science knowledge stack. Moreover, data scientists could enhance their work by integrating important spatial concepts and tools from GIS and cartography into data science workflows. A non-exhaustive knowledge stack for spatial data scientists, including typical tasks and tools, is given in Table 1.{$<$}/p{$><$}p{$>$}There are many interesting ongoing projects at the interface of spatial and data science. Examples from the ArcGIS platform include:{$<$}/p{$><$}ul{$><$}li{$>$}Integration of Python GIS APIs with Machine Learning libraries, such as scikit-learn or TensorFlow, in Jupyter Notebooks{$<$}/li{$><$}li{$>$}Combination of R (advanced statistics and visualization) and GIS (basic geoprocessing, mapping) in ModelBuilder and other automatization frameworks{$<$}/li{$><$}li{$>$}Enterprise GIS solutions for distributed geoprocessing operations on big, real-time vector and raster datasets{$<$}/li{$><$}li{$>$}Dashboards for visualizing real-time sensor data and integrating it with other data sources{$<$}/li{$><$}li{$>$}Applications for interactive data exploration{$<$}/li{$><$}li{$>$}GIS tools for Machine Learning tasks for prediction, clustering and classification of spatial data{$<$}/li{$><$}li{$>$}GIS Integration for Hadoop{$<$}/li{$><$}/ul{$><$}p{$>$}While the discussion about proprietary (ArcGIS) vs. open-source (QGIS) software is beyond the scope of this article, it has to be stated that a.) many ArcGIS projects are actually open-source and b.) using a complete GIS platform instead of several open-source pieces has several advantages, particularly in efficiency, maintenance and support (see Wilkening et al. (2019) for a more detailed consideration). At any rate, cartography and GIS tools are the essential technology blocks for solving the (80\% spatial) data science problems of the future.{$<$}/p{$>$}},
  journaltitle = {Abstracts of the ICA},
  date = {2019-07-15},
  pages = {1-2},
  author = {Wilkening, Jan},
  file = {/home/robin/Dropbox/Biblio/Wilkening/Wilkening_2019_Towards_Spatial_Data_Science.pdf}
}

@article{meier_relevance_2019,
  langid = {english},
  title = {On the Relevance of Cartography \&ndash; {{An}} Interaction Design Perspective},
  volume = {2},
  issn = {-},
  url = {https://www.proc-int-cartogr-assoc.net/2/84/2019/},
  doi = {10/gf7hmd},
  abstract = {{$<$}p{$><$}strong{$>$}Abstract.{$<$}/strong{$>$} We see more cartographic products in our digital world than ever before. But what role does cartography play in the modern production of cartographic products? In this position paper, we will argue that the democratization and diffusion of cartographic production has also led to the presumed “fading relevance” of cartography. As an argument against this notion, we highlight starting points for the field of cartography to improve modern cartographic production through its inherent cartographic knowledge.{$<$}/p{$>$}},
  journaltitle = {Proceedings of the ICA},
  date = {2019-07-10},
  pages = {1-6},
  author = {Meier, Sebastian and Tost, Jordi and Heidmann, Frank},
  file = {/home/robin/Dropbox/Biblio/Meier_Tostet-al/Meier_Tostet-al_2019_On_the_relevance_of_cartography_&ndash\;_An.pdf}
}

@article{khayat_validity_2019,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1907.13314},
  title = {The {{Validity}}, {{Generalizability}} and {{Feasibility}} of {{Summative Evaluation Methods}} in {{Visual Analytics}}},
  issn = {1077-2626, 1941-0506, 2160-9306},
  url = {http://arxiv.org/abs/1907.13314},
  doi = {10/gf7hmh},
  abstract = {Many evaluation methods have been used to assess the usefulness of Visual Analytics (VA) solutions. These methods stem from a variety of origins with different assumptions and goals, which cause confusion about their proofing capabilities. Moreover, the lack of discussion about the evaluation processes may limit our potential to develop new evaluation methods specialized for VA. In this paper, we present an analysis of evaluation methods that have been used to summatively evaluate VA solutions. We provide a survey and taxonomy of the evaluation methods that have appeared in the VAST literature in the past two years. We then analyze these methods in terms of validity and generalizability of their findings, as well as the feasibility of using them. We propose a new metric called summative quality to compare evaluation methods according to their ability to prove usefulness, and make recommendations for selecting evaluation methods based on their summative quality in the VA domain.},
  journaltitle = {IEEE Transactions on Visualization and Computer Graphics},
  shortjournal = {IEEE Trans. Visual. Comput. Graphics},
  date = {2019},
  pages = {1-1},
  keywords = {Computer Science - Human-Computer Interaction},
  author = {Khayat, Mosab and Karimzadeh, Morteza and Ebert, David S. and Ghafoor, Arif},
  file = {/home/robin/Dropbox/Biblio/Khayat_Karimzadehet-al/Khayat_Karimzadehet-al_2019_The_Validity,_Generalizability_and_Feasibility_of.pdf}
}

@article{popelka_user_2019,
  langid = {english},
  title = {User {{Evaluation}} of {{Map}}-{{Based Visual Analytic Tools}}},
  volume = {8},
  url = {https://www.mdpi.com/2220-9964/8/8/363},
  doi = {10/gf7hmg},
  abstract = {Big data have also become a big challenge for cartographers, as the majority of big data may be localized. The use of visual analytics tools, as well as comprising interactive maps, stimulates inter-disciplinary actors to explore new ideas and decision-making methods. This paper deals with the evaluation of three map-based visual analytics tools by means of the eye-tracking method. The conceptual part of the paper begins with an analysis of the state-of-the-art and ends with the design of proof-of-concept experiments. The verification part consists of the design, composition, and realization of the conducted eye-tracking experiment, in which three map-based visual analytics tools were tested in terms of user-friendliness. A set of recommendations on GUI (graphical user interface) design and interactive functionality for map makers is formulated on the basis of the discovered errors and shortcomings in the assessed stimuli. The results of the verification were used as inputs for improving the three tested map-based visual analytics tools and might serve as a best practice for map-based visual analytics tools in general, as well as for improving the policy making cycle as elaborated by the European project PoliVisu (Policy Development based on Advanced Geospatial Data Analytics and Visualization).},
  number = {8},
  journaltitle = {ISPRS International Journal of Geo-Information},
  date = {2019-08},
  pages = {363},
  keywords = {usability,visual analytics,eye-tracking,HSLayers NG,interactive map,PoliVisu,WebGLayer},
  author = {Popelka, Stanislav and Herman, Lukáš and Řezník, Tomas and Pařilová, Michaela and Jedlička, Karel and Bouchal, Jiří and Kepka, Michal and Charvát, Karel},
  file = {/home/robin/Dropbox/Biblio/Popelka_Hermanet-al/Popelka_Hermanet-al_2019_User_Evaluation_of_Map-Based_Visual_Analytic_Tools.pdf}
}

@article{silva_visual_2019,
  langid = {english},
  title = {Visual Analytics for Spatiotemporal Events},
  issn = {1573-7721},
  url = {https://doi.org/10.1007/s11042-019-08012-2},
  doi = {10/gf7hmf},
  abstract = {Crimes, forest fires, accidents, infectious diseases, or human interactions with mobile devices (e.g., tweets) are being logged as spatiotemporal events. For each event, its geographic location, time and related attributes are known with high levels of detail (LoDs). The LoD plays a crucial role when analyzing data, as it can highlight useful patterns or insights and enhance the user’ perception of phenomena. For this reason, modeling phenomena at different LoDs is needed to increase the analytical value of the data, as there is no exclusive LOD at which the data can be analyzed. Current practices work mainly on a single LoD of the phenomena, driven by the analysts’ perception, ignoring that identifying the suitable LoDs is a key issue for pointing relevant patterns. This article presents a Visual Analytics approach called VAST, that allows users to simultaneously inspect a phenomenon at different LoDs, helping them to see in what LoDs do interesting patterns emerge, or in what LoDs the perception of the phenomenon is different. In this way, the analysis of vast amounts of spatiotemporal events is assisted, guiding the user in this process. The use of several synthetic and real datasets supported the evaluation and validation of VAST, suggesting LoDs with different interesting spatiotemporal patterns and pointing the type of expected patterns.},
  journaltitle = {Multimedia Tools and Applications},
  shortjournal = {Multimed Tools Appl},
  date = {2019-08-16},
  keywords = {Data visualization,Visual analytics,Multiple levels of detail,Spatiotemporal patterns},
  author = {Silva, Ricardo Almeida and Pires, João Moura and Datia, Nuno and Santos, Maribel Yasmina and Martins, Bruno and Birra, Fernando},
  file = {/home/robin/Dropbox/Biblio/Silva_Pireset-al/Silva_Pireset-al_2019_Visual_analytics_for_spatiotemporal_events.pdf}
}

@inproceedings{rothinteractive,
  location = {{Tokyo}},
  title = {Interactive \& Multiscale Thematic Maps: {{A}} Preliminary Study},
  eventtitle = {{{ICC}} 2019},
  keywords = {⛔ No DOI found},
  author = {Roth, Robert E and Kelly, Meghan and Underwood, Nick and Lally, Nick and Vincentc, Kristen and Sack, Carl},
  file = {/home/robin/Dropbox/Biblio/Roth_Kellyet-al/Roth_Kellyet-al_Interactive_&_multiscale_thematic_maps.pdf}
}

@unpublished{cura:halshs-02290556,
  venue = {{Mondorf-les-Bains, Luxembourg}},
  title = {Enriching {{Exploratory Spatial Data Analysis}} with Modern Computer Tools},
  url = {https://halshs.archives-ouvertes.fr/halshs-02290556},
  eventtitle = {{{ECTQG}} 2019},
  date = {2019-09},
  keywords = {Columnar DBMS,ESDA,Geographic Data Analysis,Geovisual Analytics,Large data},
  author = {Cura, Robin},
  hal_id = {halshs-02290556},
  hal_version = {v1}
}

@inbook{cura_visualisation_2020,
  langid = {french},
  location = {{Paris}},
  title = {Visualisation},
  booktitle = {Modélisation des villes et des territoires},
  publisher = {{ISTE}},
  date = {2020},
  pages = {300--340},
  author = {Cura, Robin},
  bookauthor = {Pumain, Denise}
}

@inproceedings{tannier:halshs-01003259,
  location = {{Alba Iulia, Romania}},
  title = {Sharing and Disseminating Knowledge of Advanced Spatial Modeling. {{Presentation}} of an Action Carried out by the {{European}} Research Group S4 (Spatial Simulation for Social Sciences)},
  url = {https://halshs.archives-ouvertes.fr/halshs-01003259},
  booktitle = {International {{Conference}} of {{Territorial Intelligence}}},
  date = {2006-09},
  pages = {8},
  keywords = {géographie,Internet,geography,Intelligence Territorial,knowledge dissemination,simulation spatiale,spatial modelling,spatial simulation,Territorial Intelligence},
  author = {Tannier, Cécile},
  pdf = {https://halshs.archives-ouvertes.fr/halshs-01003259/file/INTI-2006-Alba-Tannier.pdf},
  hal_id = {halshs-01003259},
  hal_version = {v1}
}

@article{brunet1980composition,
  title = {La Composition Des Modèles Dans l'analyse Spatiale},
  doi = {10/gf9f5z},
  journaltitle = {L'Espace géographique},
  date = {1980},
  pages = {253-265},
  author = {Brunet, Roger},
  publisher = {{JSTOR}}
}

@article{josselin_presentation_2006,
  langid = {english},
  title = {Presentation : {{Spatial Analysis}} and {{GEOmatics}}. {{Conference SAGEO}}'2005, {{Avignon}}, {{France}}},
  issn = {1278-3366},
  url = {http://journals.openedition.org/cybergeo/2909},
  doi = {10/bwdsn9},
  shorttitle = {Presentation},
  abstract = {SAGEO is the annual International Conference on Spatial Analysis and GEOmatics. It aims to: present recent and high quality research in the field of Geomatics and Spatial Analysis, bring together researchers from various disciplines, provide an exchange platform on research and development in Geomatics, on a national and international level, for public or private bodies. SAGEO is a good opportunity for two complementary research networks to meet and to discuss their points of view on spatial...},
  journaltitle = {Cybergeo : European Journal of Geography},
  date = {2006-10-25},
  author = {Josselin, Didier and Libourel, Thérèse}
}

@article{reuillon_new_2015,
  title = {A {{New Method}} to {{Evaluate Simulation Models}}: {{The Calibration Profile}} ({{CP}}) {{Algorithm}}},
  volume = {18},
  issn = {1460-7425},
  url = {http://jasss.soc.surrey.ac.uk/18/1/12.html},
  doi = {10/gf9f5x},
  shorttitle = {A {{New Method}} to {{Evaluate Simulation Models}}},
  number = {1},
  journaltitle = {Journal of Artificial Societies and Social Simulation},
  shortjournal = {JASSS},
  date = {2015},
  pages = {12},
  author = {Reuillon, Romain and Schmitt, Clara and De Aldama, Ricardo and Mouret, Jean-Baptiste}
}

@thesis{nahassia_formes_2019,
  langid = {french},
  location = {{Paris}},
  title = {Formes spatiales et temporelles du changement urbain. Analyser la localisation des activités à Tours sur 2 000 ans.},
  abstract = {Cette thèse a pour objet les formes spatiales et temporelles du changement urbain dans la très longue durée, étudiées au travers des activités et de leurs localisations dans l’espace urbain. Pour cela, elle s’appuie sur le cas de Tours et sur des données archéologiques, les «~Objets Historiques~», observés depuis le 1er siècle av. J.-C. Les localisations des activités sont appréhendées dans une perspective spatio-temporelle. Un type d’activité est-il toujours situé au même endroit relativement au contexte urbain~? Peut-on identifier des effets de voisinage entre activités~? Les types de localisation changent-ils selon les époques, et selon quelles temporalités~?
Pour répondre à ces questions et aux enjeux spécifiques de la longue durée – incomplétude des connaissances, complexité de l’identification du changement à une résolution temporelle fine, hétérogénéité des données, etc. –, une démarche articulant la construction conceptuelle, l’analyse empirique et la modélisation du changement a été mise en place. Cette démarche est en outre structurée par une réflexion interdisciplinaire et reproductible. Des méthodes originales d’analyse, statistiques et spatiales, ont été construites et s’appuient sur la représentation, la modélisation graphique et la géovisualisation.~Une plateforme interactive a ainsi été développée pour explorer les résultats dans un dialogue entre le particulier et le général.
La combinaison de ces approches permet d’établir des profils de localisation des activités au cours du temps, d’identifier des motifs spatiaux et de quantifier des temporalités du changement, confirmant notamment le caractère progressif et multi-temporel des transformations de l’espace urbain.},
  pagetotal = {466},
  institution = {{Université Paris 1 Panthéon-Sorbonne}},
  type = {Thèse de Doctorat},
  date = {2019-09-27},
  author = {Nahassia, Lucie},
  file = {/home/robin/Dropbox/Biblio/Nahassia/Nahassia_2019_Formes_spatiales_et_temporelles_du_changement_ebook.pdf;/home/robin/Dropbox/Biblio/Nahassia/Nahassia_2019_Formes_spatiales_et_temporelles_du_changement.pdf}
}

@thesis{gravier_deux_2018,
  langid = {french},
  location = {{Paris}},
  title = {Deux mille ans d'une ville en système. Proposition d'une démarche appliquée au cas de Noyon},
  url = {http://www.theses.fr/s91330},
  abstract = {L’objet de cette thèse est de comprendre l’évolution d’une ville sur toute la durée de son existence. Elle se fonde sur le cas de Noyon, dont l’origine remonte au 1er s. apr. J.-C. La démarche est schématiquement décomposée en trois temps. Il s’agit tout d’abord d’étudier la structure intra-urbaine fonctionnelle et d’en identifier la trajectoire sur 2~000~ans. Puis nous appréhendons la position relative de la ville – saisie d’un point de vue politico-administratif, économique et spatial – par rapport aux autres villes avec lesquelles elle est en interaction. La confrontation de la trajectoire intra-urbaine et de la position relative de la ville permet enfin d’examiner ce qui unit l’histoire d’une ville avec l’histoire des villes avec lesquelles elle fait système.
La très longue durée considérée fait émerger deux enjeux majeurs. D’une part, les sociétés étudiées sur 2~000~ans sont très différentes. L’enjeu est donc de les comparer, ce qui implique de questionner la pérennité de la signification des objets spatio-temporels étudiés pour reconstituer leurs trajectoires. D’autre part, cette approche requiert l’étude de données archéologiques, textuelles et iconographiques, qui sont lacunaires et imprécises, en particulier pour l’étude de phénomènes à petite échelle. Un des défis du travail consiste donc à mener une véritable enquête à partir de laquelle on doit cumuler les indices pour tenter de reconstituer d’anciennes réalités spatiales. Tout cela demande finalement d’élaborer de nouvelles approches méthodologiques et d’expliciter les chemins relatifs à la construction des connaissances afin de proposer une étude des villes en système sur le temps long qui soit reproductible.},
  pagetotal = {404},
  institution = {{Université Paris 1 Panthéon-Sorbonne}},
  type = {Thèse de Doctorat},
  date = {2018-12-05},
  keywords = {Geographie},
  author = {Gravier, Julie},
  file = {/home/robin/Dropbox/Biblio/Gravier/Gravier_2018_Deux_mille_ans_d'une_ville_en_système.pdf}
}

@inproceedings{cura:halshs-02296147,
  langid = {french},
  location = {{Paris, France}},
  title = {Comprendre les dynamiques d'un territoire qui n'existe plus : quelles alternatives au terrain pour l'étude d'un espace sur le temps long ?},
  url = {https://halshs.archives-ouvertes.fr/halshs-02296147},
  shorttitle = {Comprendre les dynamiques d'un territoire qui n'existe plus},
  abstract = {La discussion que nous proposons découle d’une caractéristique commune rencontrée dans le cadre de nos thèses : travaillant tous trois sur l’analyse de transformations socio-spatiales de systèmes de peuplement survenues sur le temps très long (plusieurs siècles à plusieurs millénaires), nos terrains d’étude recouvrent des espaces du passé. Seulement quelques traces observables en subsistent, telles que des orientations et des formes viaires inaltérées, des monuments historiques ou encore des vestiges archéologiques. Somme toute, des données bien insuffisantes pour facilement appréhender l’espace étudié tant globalement que dans ses spécificités. Cette carence dans l’appréhension directe de nos espaces d’étude ne peut pas, en outre, être compensée par un recours à d’éventuels acteurs puisque leur durée de vie est de fait largement inférieure au temps long de nos objets d’étude. Les possibilités d’enquêtes de terrain nous étant limitées, nous ne pouvons dès lors aborder nos espaces qu’à partir de sources indirectes, ancrant notre démarche dans « une [recherche] de seconde main » (Claval, 2013). Face à ce constat, peu fréquent en géographie, nous proposons une réflexion croisée sur nos rapports à des terrains « infréquentables » physiquement, et donc a priori alternatifs vis-à-vis de la « géographie de terrain » qui prédomine aujourd’hui. Nos expériences de recherche s’attachent à des espaces et des échelles divers. Lucie Nahassia travaille sur la dynamique intra-urbaine à partir des localisations des activités en ville à travers le cas de Tours du 1er au 21e siècle. Elle s’appuie pour cela sur des sources collectées par des archéologues de l’urbain, provenant en particulier d’éléments matériels issus de fouilles archéologiques, compilées sous forme de bases de données. Ces sources sont ensuite complétées par des discours d’experts : entretiens avec des spécialistes de l’histoire de Tours et bibliographie historique, archéologique et géographique sur la ville. Julie Gravier cherche à comprendre la trajectoire de la ville de Noyon au sein du système urbain du nord de la France dans lequel la ville s’inscrit (également du 1er au 21e siècle). Ses données sont issues de ses propres fouilles archéologiques, de documents iconographiques et textuels d’archives, et de la documentation de synthèse historique relative aux villes étudiées - écrite majoritairement par des archéologues et des historiens. L’aire d’étude de Robin Cura est plus large et imprécise : il cherche à modéliser les transformations spatiales génériques s’étant produites en Europe du Nord-Ouest, entre le 9e et le 12e siècle, à partir d’un exemple illustré par la région de Tours. Cette modélisation se fonde entièrement sur des entretiens réalisés dans le cadre d’une collaboration avec des experts historiens et archéologues, eux-mêmes appuyant leurs discours sur des données issues de fouilles et de sources textuelles. Tant dans les régions que dans les échelles, les sources de données et les modes de collecte de l’information, nos trois objets de recherche sont distincts. De même, nos approches pour les traiter sont multiples. Depuis l’observation et l’exploration des données jusqu’à la simulation informatique, en passant par les méthodes de (géo-)statistiques descriptives et d’analyses factorielles, nos outils méthodologiques et nos manières de synthétiser nos terrains diffèrent grandement. Toutefois, dans cette diversité, nous sommes confrontés à des questionnements semblables face au terrain. Tout d’abord, contrairement à un espace d’étude contemporain, les territoires que nous étudions n’existent plus et nous sommes dans l’obligation de reconstruire ce qui a existé à un moment donné dans le temps. Nos terrains ne sont pas des observables mais des construits. De ce fait, nous n’entretenons un rapport ni perceptif, ni sensible au terrain : ne pouvant pas nous y rendre physiquement, nous recréons nos terrains, qui sont donc mentaux, voire virtuels dans le cas de l’utilisation de la simulation multi-agents par L. Nahassia et R. Cura. Ensuite, contrairement à de nombreuses études sur les systèmes de peuplement actuels, la définition de notre terrain ne peut pas être établie a priori sur la base de maillages territoriaux identifiés à un moment donné tant ces derniers ont pu évoluer au cours des périodes étudiées : la « commune de Noyon » n’a pas de sens sur 2000 ans. Pour que le terrain que nous choisissons ait un sens par rapport à nos objets de recherche, nous sommes dans l’obligation de questionner et d’étudier nos aires d’étude avant de définir spatialement un espace de référence. De ce fait, bien que nos objets de recherche et nos approches méthodologiques nous ancrent dans le champ de la géographie théorique et quantitative, il nous semble que notre rapport au terrain s’en démarque en proposant une vision alternative des manières de le définir, finalement proche d’une géographie plus qualitative. Enfin, nos sources sont principalement secondaires ou tertiaires (par entretien avec des experts). En ce sens, « ce qui fait notre terrain » peut se rapporter à une posture d’ethnographe - comme celle exprimée par Yann Calbérac (2011) dans son travail épistémologique, qui définit son terrain à travers « les géographes [qu’il] interroge [et qui] produisent des espaces lorsqu’ils font du terrain ». Comme lui, nous estimons avoir « bel et bien un terrain même si [nous] ne [pouvons] le fréquenter » (ibid.). Nos terrains, si particuliers car ancrés dans le passé, sont donc alternatifs vis-à-vis de notre cadre théorique de référence. Pour autant, l’outillage que nous déployons pour les construire ne s’inscrit-il pas finalement dans une tradition classique, antérieure à la géographie de terrain, de « géographie de cabinet » telle que définie (ibid.) par Paul Claval ? Références Calberac, Yann, « Le terrain des géographes est-il un terrain géographique ? Le terrain d’un épistémologue », Carnets de géographes, 2 (2011). Claval, Paul, « Le rôle du terrain en géographie. Des épistémologies de la curiosité à celles du désir », Confins (2013).},
  booktitle = {Journée des jeunes chercheurs de l'Institut de Géographie de Paris (JIG 2017)},
  date = {2017-04-06},
  keywords = {⛔ No DOI found,Dynamiques spatiales,Temps-long,Terrain alternatif,Terrains du passé},
  author = {Cura, Robin and Gravier, Julie and Nahassia, Lucie},
  file = {/home/robin/Dropbox/Biblio/Cura_Gravieret-al/Cura_Gravieret-al_2017_Comprendre_les_dynamiques_d'un_territoire_qui.pdf},
  ids = {cura:halshs-02296147},
  organization = {{{{Ecole Doctorale de Géographie de Paris}}}},
  hal_id = {halshs-02296147},
  hal_version = {v1}
}

@article{rodier_modelisation_2010,
  langid = {french},
  title = {Modélisation des objets historiques selon la fonction, l’espace et le temps pour l’étude des dynamiques urbaines dans la longue durée},
  issn = {1278-3366},
  url = {http://journals.openedition.org/cybergeo/23175},
  doi = {10/bn4kbx},
  abstract = {Le principe de compréhension de l’espace urbain proposé consiste à aborder la ville comme un ensemble d’objets complexes selon une approche systémique. Le système ville considéré pour étudier la fabrique de la ville dans la longue durée est constitué de trois dimensions dont relèvent les objets historiques de l’échelle de la fouille à celle de l’espace urbanisé ancien : fonctionnelle (usage social), spatiale (localisation, étendue et morphologie) et temporelle (datation, durée et chronologie). L’objet historique constitue l’unité analytique de l’espace étudié. Il est le produit cartésien des trois ensembles Fonction, Espace, Temps dont il est issu. Partant de ce processus, l’Objet Historique (OH) est déstructuré en trois types d’objets simples, l’entité fonctionnelle (EF), l’entité spatiale (ES) et l’entité temporelle (ET). - L’approche thématique de l’OH en milieu urbain est fonctionnelle, organisée selon un thésaurus hiérarchisé.- L’espace, ensemble le plus formalisé des trois, est structuré sur le modèle d’un graphe planaire topologique sans isthme. - Le temps, toujours considéré comme continu et linéaire, sera modélisé par analogie à l’espace en utilisant la topologie temporelle définie en intelligence artificielle. Les associations entre les trois ensembles caractérisent chacune une interaction (fonction-espace, fonction-temps, espace-temps ou encore fonction-espace-temps). Elles permettent, au-delà de la reconstruction de l’OH, l’observation des transformations urbaines par l’analyse des distributions et de la cartographie de chacune des entités seule ou deux à deux.L’originalité de la démarche réside dans une approche qui permet de ne pas partir de la cartographie d’un phénomène à un temps t1 et de la comparer à celle d’un temps t2, mais de l’aborder indifféremment selon une entrée fonctionnelle, spatiale ou temporelle. La valeur heuristique de cette modélisation réside dans le passage de la description (quoi, où, quand) à la compréhension des phénomènes de transformation (comment, pourquoi).},
  journaltitle = {Cybergeo : European Journal of Geography},
  date = {2010-06-17},
  author = {Rodier, Xavier and Saligny, Laure},
  file = {/home/robin/Dropbox/Biblio/Rodier_Saligny/Rodier_Saligny_2010_Modélisation_des_objets_historiques_selon_la.pdf}
}

@article{wang_techniques_2019,
  title = {Techniques for {{Accelerating Aggregated Range Queries}} on {{Large Multidimensional Datasets}} in {{Interactive Visual Exploration}}},
  date = {2019},
  keywords = {Visual analytics,⛔ No DOI found,DBMS,Analytics DBMS},
  author = {Wang, Zhe},
  file = {/home/robin/Dropbox/Biblio/Wang/Wang_2019_Techniques_for_Accelerating_Aggregated_Range.pdf}
}

@incollection{chenisms,
  title = {“{{Isms}}” in Visualization},
  abstract = {In visualization, there are many different wisdoms and opinions about why visualization works, what makes a good visualization, and how to design and evaluate visualization.
Collectively these wisdoms and options have shaped a landscape of the schools of thought in the field of visualization.
In this chapter, we examine various schools of thought in visualization, juxtaposing them with schools of thought in computer science and psychology.
We deliberate the possibility that some schools of thought in computer science and psychology may have influenced those in visualization.
Based on our observation of the development of schools of thought in the discipline of psychology, we believe that it is the empirical evidence that informs the development of theories, which are often embedded in some schools of thought.
Meanwhile, empirical studies have crucial role in visualization to inform and validate postulated theories.},
  number = {11},
  booktitle = {Foundations of {{Data Visualization}}},
  publisher = {{Springer International Publishing}},
  date = {2020},
  author = {Chen, Min and Edwards, Darren J.},
  file = {/home/robin/Dropbox/Biblio/Chen_Edwards/Chen_Edwards_2020_“Isms”_in_visualization.pdf}
}

@article{apple_statistical_2019,
  title = {Statistical {{Mapping}} ({{Enumeration}}, {{Normalization}}, {{Classification}})},
  volume = {2019},
  issn = {25772848},
  url = {https://gistbok.ucgis.org/bok-topics/statistical-mapping-enumeration-normalization-classification},
  doi = {10/gf9f5w},
  number = {Q2},
  journaltitle = {Geographic Information Science \& Technology Body of Knowledge},
  shortjournal = {GIS\&T BoK},
  date = {2019-04-01},
  author = {{Apple} and Foster, Michael}
}

@article{han_rankbrushers_2019,
  langid = {english},
  title = {{{RankBrushers}}: Interactive Analysis of Temporal Ranking Ensembles},
  issn = {1875-8975},
  url = {https://doi.org/10.1007/s12650-019-00598-x},
  doi = {10/gf9f5v},
  shorttitle = {{{RankBrushers}}},
  abstract = {Temporal ranking ensembles indicate time-evolving multivariate rankings. Such data can be commonly found in our daily life, for example, different rankings of universities (QS, ARWU, THE, and USNews) over year and those of NBA players over season. Effective analysis and tracking of rankings allow users to gain insights into the overall ranking change over time and seek the explanation for the change. This paper introduces a novel visual analytics approach for characterizing and visualizing the uncertainty, dynamics, and differences of ranking ensemble data. A novel visual design is proposed to characterize the evolution pattern, distribution, and uncertainty of a large number of temporal ranking ensembles. The evolutionary ranking ensembles are progressively explored, tracked, and compared by means of an intuitive visualization system. Two case studies and a task-driven user study conducted on real datasets demonstrate the effectiveness and feasibility of the implemented system.Graphic abstract Open image in new window},
  journaltitle = {Journal of Visualization},
  shortjournal = {J Vis},
  date = {2019-09-23},
  keywords = {Rank,Rank-Clocks,Temporal ranking ensembles,TrajPop,Uncertainty,Visualization},
  author = {Han, Dongming and Pan, Jiacheng and Guo, Fangzhou and Luo, Xiaonan and Wu, Yingcai and Zheng, Wenting and Chen, Wei},
  file = {/home/robin/Dropbox/Biblio/Han_Panet-al/Han_Panet-al_2019_RankBrushers.pdf}
}

@inproceedings{wenskovitch_machine_2018,
  langid = {english},
  location = {{Berlin}},
  title = {Machine {{Learning}} from {{User Interaction}} for {{Visualization}} and {{Analytics}}: {{A Workshop}}-{{Generated Research Agenda}}},
  url = {https://learningfromusersworkshop.github.io/workshop2018.html},
  shorttitle = {Machine {{Learning}} from {{UserInteraction}} for {{Visualization}} and {{Analytics}} Workshop},
  eventtitle = {{{IEEE VIS}} 2018},
  booktitle = {Machine {{Learning}} from {{UserInteraction}} for {{Visualization}} and {{Analytics}} Workshop},
  date = {2018},
  author = {Wenskovitch, John and Dowling, Michelle and Grose, Laura and North, Chris and Chang, Remco and Endert, Alex and Rogers, David H.},
  file = {/home/robin/Dropbox/Biblio/Wenskovitch_Dowlinget-al/Wenskovitch_Dowlinget-al_2018_Machine_Learning_from_User_Interaction_for.pdf}
}


